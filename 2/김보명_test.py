# -*- coding: utf-8 -*-
"""ê¹€ë³´ëª…_test.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xtQVIGsqJYtLY5oKaHSr4ctZdiS49JgR

# AI í’ˆì§ˆ í‰ê°€ ëª¨ë¸ í•™ìŠµ - KLUE-RoBERTa-large
ì´ ë…¸íŠ¸ë¶ì€ AI ì‘ë‹µ í’ˆì§ˆ í‰ê°€ë¥¼ ìœ„í•œ Multi-label Classification ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤.

í‰ê°€ ê¸°ì¤€ (9ê°œ):

*   linguistic_acceptability (ì–¸ì–´ì  ìˆ˜ìš©ì„±)
*   consistency (ì¼ê´€ì„±)
*   interestingness (í¥ë¯¸ë¡œì›€)
*   unbias (í¸í–¥ ì—†ìŒ)
*   harmlessness (ë¬´í•´ì„±)
*   no_hallucination (í™˜ê° ì—†ìŒ)
*   understandability (ì´í•´ ê°€ëŠ¥ì„±)
*   sensibleness (í•©ë¦¬ì„±)
*   specificity (êµ¬ì²´ì„±)

# 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° ì„í¬íŠ¸
"""

!pip install torch transformers datasets pandas scikit-learn tqdm -q

from google.colab import drive
drive.mount('/content/drive/')

import pandas as pd
import numpy as np
import torch
from torch.utils.data import Dataset, DataLoader
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    TrainingArguments,
    Trainer,
)
from sklearn.metrics import accuracy_score, f1_score, classification_report
from tqdm.auto import tqdm
from torch.utils.data import Dataset, Sampler
import warnings

warnings.filterwarnings('ignore')

# GPU í™•ì¸
device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')
print(f"Using device: {device}")

"""# ì„¤ì •"""

# ëª¨ë¸ ë° í•™ìŠµ ì„¤ì •
MODEL_NAME = "klue/roberta-base"
MAX_LENGTH = 256
BATCH_SIZE = 128
LEARNING_RATE = 2e-5
NUM_EPOCHS = 3
SEED = 42

# í‰ê°€ ê¸°ì¤€ (íƒ€ê²Ÿ ì»¬ëŸ¼)
CRITERIA = [
    'linguistic_acceptability',
    'consistency',
    'interestingness',
    'unbias',
    'harmlessness',
    'no_hallucination',
    'understandability',
    'sensibleness',
    'specificity'
]
NUM_LABELS = len(CRITERIA)

# ì‹œë“œ ê³ ì •
torch.manual_seed(SEED)
np.random.seed(SEED)

train_df = pd.read_csv('/content/drive/MyDrive/ai_á„’á…¥á„‡á…³_á„ƒá…¦á„‹á…µá„á…¥á„‰á…¦á†º/data/train/training_all_aggregated.csv', encoding='utf-8-sig')
val_df = pd.read_csv('/content/drive/MyDrive/ai_á„’á…¥á„‡á…³_á„ƒá…¦á„‹á…µá„á…¥á„‰á…¦á†º/data/val/validation_all_aggregated.csv', encoding='utf-8-sig')

print(f"Training ë°ì´í„°: {len(train_df):,}ê°œ")
print(f"Validation ë°ì´í„°: {len(val_df):,}ê°œ")

print(train_df.iloc[0])

"""# ë°ì´í„°ì˜ íˆ¬í‘œ ìˆ˜ ë¹„ìœ¨ ë³€í™˜ ë° ê° ìƒ˜í”Œì˜ ë‚œì´ë„ ìˆ˜ì¹˜í™”"""

def prepare_context_data(df, max_prev_turns=3):
    # 1. ì •ë ¬: ëŒ€í™” ì„¸ì…˜ë³„ë¡œ ë¬¶ê³  ì¸ë±ìŠ¤ ìˆœì„œëŒ€ë¡œ ì •ë ¬ (ì—ëŸ¬ ë°©ì§€ìš©Kind Stable ì‚¬ìš©)
    df = df.sort_values(['conversation_id']).sort_index(kind='stable').reset_index(drop=True)

    # 2. 'ì´ì „ ì§ˆë¬¸ + ì‘ë‹µ' í•©ì¹œ í…ìŠ¤íŠ¸ ë§Œë“¤ê¸° (QA ìŒ ìƒì„±)
    df['qa_pair'] = "Q: " + df['human_question'].astype(str) + " A: " + df['bot_response'].astype(str)

    # 3. ê·¸ë£¹ë³„ë¡œ ì´ì „ ëŒ€í™”ë“¤ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë¬¶ê¸°
    def get_history(group):
        history = []
        res = []
        for i in range(len(group)):
            # í˜„ì¬ í–‰ ê¸°ì¤€, ì´ì „ ê¸°ë¡ë“¤ì˜ ë³µì‚¬ë³¸ì„ ì €ì¥ (í˜„ì¬ í–‰ QAëŠ” ì œì™¸)
            res.append(list(history))
            # ë‹¤ìŒ í–‰ì„ ìœ„í•´ í˜„ì¬ QA ìŒì„ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€ (ìµœëŒ€ í„´ìˆ˜ ìœ ì§€)
            history.append(group.iloc[i]['qa_pair'])
            if len(history) > max_prev_turns:
                history.pop(0)
        return pd.Series(res, index=group.index)

    print("ë©€í‹°í„´ ë§¥ë½(Context) ìƒì„± ì¤‘...")
    df['context'] = df.groupby('conversation_id', group_keys=False).apply(get_history)
    return df

# ë°ì´í„° ë¡œë“œ í›„ ë°”ë¡œ ì‹¤í–‰
train_df = prepare_context_data(train_df)
val_df = prepare_context_data(val_df)

"""# ë©€í‹°í„´ í…ŒìŠ¤íŠ¸"""

sample_id = train_df['conversation_id'].value_counts().index[0]
sample_session = train_df[train_df['conversation_id'] == sample_id][['conversation_id', 'human_question', 'bot_response', 'context']]

print(f"--- [Session ID: {sample_id}] ë§¥ë½ ìƒì„± í™•ì¸ ---")
display(sample_session.head(5))

idx = train_df[train_df['context'].apply(len) >= 1].index[0] # ë§¥ë½ì´ ìˆëŠ” ì²« ë°ì´í„° ì°¾ê¸°
row = train_df.iloc[idx]

context_text = " [SEP] ".join(row['context'])
full_text = f"{context_text} [SEP] {row['human_question']} [SEP] {row['bot_response']}"

print("--- [ìµœì¢… ëª¨ë¸ ì…ë ¥ í˜•íƒœ ì˜ˆì‹œ] ---")
print(full_text)

def preprocess_for_curriculum(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()

    # 1. í…ìŠ¤íŠ¸ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ë° ì…ë ¥ í…ìŠ¤íŠ¸ ìƒì„±
    df['human_question'] = df['human_question'].fillna('')
    df['bot_response'] = df['bot_response'].fillna('')


    df['input_text'] = df['human_question'] + ' [SEP] ' + df['bot_response']

    # 2. Soft Labels ë° ê°œë³„ ë‚œì´ë„ ê³„ì‚°
    # ê° í–‰ì˜ 'ì „ì²´ ì§€í‘œ ë‚œì´ë„'ë¥¼ í•©ì‚°í•  ë³€ìˆ˜ë¥¼ ì´ˆê¸°í™”
    df['total_difficulty'] = 0

    for c in CRITERIA:
        # íˆ¬í‘œ í•©ê³„ ê³„ì‚°
        total_votes = df[f'{c}_yes_count'] + df[f'{c}_no_count'] + 1e-8 #total_votesê°€ 0ì¼ë•Œ 0ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ì˜¤ë¥˜ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•œ ì‘ì€ê°’

        # [Soft Label] ì°¬ì„± ë¹„ìœ¨ ê³„ì‚° (0.0 ~ 1.0)
        df[f'{c}_soft'] = df[f'{c}_yes_count'] / total_votes

        # [ë‚œì´ë„ ì¸¡ì •] ë§Œì¥ì¼ì¹˜ ì—¬ë¶€ í™•ì¸
        # 3:0 í˜¹ì€ 0:3ì´ë©´ ì‰¬ì›€(0), 2:1 í˜¹ì€ 1:2ì´ë©´ ì–´ë ¤ì›€(1)ìœ¼ë¡œ íŒë‹¨
        # ë°ì´í„°ì…‹ì— ì´ë¯¸ 'unanimous' ì»¬ëŸ¼ì´ ìˆë‹¤ë©´ í™œìš©í•˜ê³ , ì—†ë‹¤ë©´ ì§ì ‘ ê³„ì‚°.
        is_hard = (df[f'{c}_yes_count'] > 0) & (df[f'{c}_no_count'] > 0)
        df['total_difficulty'] += is_hard.astype(int)

    # 3. ìµœì¢… ë‚œì´ë„ ì ìˆ˜ (0ì : ë§¤ìš° ì‰¬ì›€ ~ 9ì : ë§¤ìš° ì–´ë ¤ì›€)
    # ì´ ì ìˆ˜ëŠ” ë‚˜ì¤‘ì— CurriculumSamplerì—ì„œ í•™ìŠµ ìˆœì„œë¥¼ ì •í•˜ëŠ” ê¸°ì¤€ì´ ë¨
    return df

# ì „ì²˜ë¦¬ ì‹¤í–‰
train_df = preprocess_for_curriculum(train_df)
val_df = preprocess_for_curriculum(val_df)

# ìƒì„± ê²°ê³¼ í™•ì¸
print("--- ì „ì²˜ë¦¬ ê²°ê³¼ ìƒ˜í”Œ (ì²« 5í–‰) ---")
display(train_df[['input_text', 'total_difficulty'] + [f'{c}_soft' for c in CRITERIA[:2]]].head())

print(f"\në‚œì´ë„ ë¶„í¬:\n{train_df['total_difficulty'].value_counts().sort_index()}")

# ê°€ì¥ ì‰¬ìš´ ë°ì´í„° 1ê°œ ì¶œë ¥
print("--- [Easy] ë‚œì´ë„ 0ì  ìƒ˜í”Œ ---")
display(train_df[train_df['total_difficulty'] == 0][['input_text']].head(1))

# ê°€ì¥ ì–´ë ¤ìš´ ë°ì´í„° 1ê°œ ì¶œë ¥
max_diff = train_df['total_difficulty'].max()
print(f"\n--- [Hard] ë‚œì´ë„ {max_diff}ì  ìƒ˜í”Œ ---")
display(train_df[train_df['total_difficulty'] == max_diff][['input_text']].head(1))

"""# í…ì„œ ê°€ê³µ"""

class MultiHeadSoftDataset(Dataset):
    """ë©€í‹°í„´ Contextì™€ Soft Labelì„ ì§€ì›í•˜ëŠ” ë°ì´í„°ì…‹"""
    def __init__(self, df, tokenizer, max_length=512): # ì§€ì¹¨ì— ë”°ë¼ ê¸¸ì´ë¥¼ 512ë¡œ ëŠ˜ë¦¼
        self.df = df.reset_index(drop=True)
        self.tokenizer = tokenizer
        self.max_length = max_length
        self.target_cols = [f'{c}_soft' for c in CRITERIA]

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]

        # 1. ë§¥ë½ ì—°ê²°: [ì´ì „ ëŒ€í™”ë“¤] [SEP] [í˜„ì¬ ì§ˆë¬¸] [SEP] [ì‘ë‹µ]
        context_list = row['context']
        context_text = " [SEP] ".join(context_list) if context_list else ""

        if context_text:
            full_text = f"{context_text} [SEP] {row['human_question']} [SEP] {row['bot_response']}"
        else:
            full_text = f"{row['human_question']} [SEP] {row['bot_response']}"

        # 2. ë ˆì´ë¸” í…ì„œ ìƒì„±
        labels = torch.tensor(row[self.target_cols].values.astype(np.float32), dtype=torch.float)

        # 3. í† í°í™” (ë©€í‹°í„´ì´ë¯€ë¡œ truncationì€ ì•ìª½ì„ ìë¥´ë„ë¡ ì„¤ì • ê°€ëŠ¥í•˜ë‚˜ ê¸°ë³¸ì€ ë’¤ë¥¼ ìë¦„)
        encoding = self.tokenizer(
            full_text,
            truncation=True,
            max_length=self.max_length,
            padding='max_length',
            return_tensors='pt'
        )

        return {
            'input_ids': encoding['input_ids'].squeeze(0),
            'attention_mask': encoding['attention_mask'].squeeze(0),
            'labels': labels,
            'difficulty': torch.tensor(row['total_difficulty'], dtype=torch.float)
        }

class CurriculumSampler(Sampler):
    """ì—í­ë³„ë¡œ ì‹ ê·œ ë‚œì´ë„ëŠ” 100%, ì´ë¯¸ ë°°ìš´ ë‚œì´ë„ëŠ” 50%ë§Œ ë³µìŠµí•˜ëŠ” ìƒ˜í”ŒëŸ¬"""
    def __init__(self, dataset_df, total_epochs, review_ratio=0.5):
        self.df = dataset_df
        self.total_epochs = total_epochs
        self.current_epoch = 0
        self.review_ratio = review_ratio # ë³µìŠµ ë°ì´í„° ë¹„ì¤‘ (0.5 = 50%)

        # ë‚œì´ë„ ì ìˆ˜(0~9ì )ë¥¼ ë¯¸ë¦¬ ê°€ì ¸ì˜µë‹ˆë‹¤.
        self.difficulties = self.df['total_difficulty'].values

    def set_epoch(self, epoch):
        self.current_epoch = epoch

    def __iter__(self):
        # 1. í˜„ì¬ ì—í­ì˜ ìµœëŒ€ ë‚œì´ë„ì™€ ì´ì „ ì—í­ì˜ ìµœëŒ€ ë‚œì´ë„ ê³„ì‚°
        current_max = ((self.current_epoch + 1) / self.total_epochs) * 9
        prev_max = (self.current_epoch / self.total_epochs) * 9 if self.current_epoch > 0 else -1

        # 2. ë°ì´í„° ë¶„ë¥˜
        # [ì‹ ê·œ]: ì´ë²ˆ ì—í­ì—ì„œ ì²˜ìŒ ë°°ìš°ëŠ” ë‚œì´ë„ êµ¬ê°„
        new_indices = np.where((self.difficulties > prev_max) & (self.difficulties <= current_max))[0]
        # [ë³µìŠµ]: ì´ì „ ì—í­ì—ì„œ ì´ë¯¸ ë§ˆìŠ¤í„°í•œ ë‚œì´ë„ êµ¬ê°„
        old_indices = np.where(self.difficulties <= prev_max)[0]

        # 3. ë³µìŠµ ë°ì´í„°ë§Œ 50% ìƒ˜í”Œë§
        if len(old_indices) > 0:
            num_to_review = int(len(old_indices) * self.review_ratio)
            sampled_old_indices = np.random.choice(old_indices, num_to_review, replace=False)
        else:
            sampled_old_indices = np.array([], dtype=int)

        # 4. ì‹ ê·œ ë°ì´í„° ì „ì²´ + ìƒ˜í”Œë§ëœ ë³µìŠµ ë°ì´í„° í•©ì¹˜ê¸°
        final_indices = np.concatenate([new_indices, sampled_old_indices])

        # ë¬´ì‘ìœ„ë¡œ ì„ê¸°
        np.random.shuffle(final_indices)

        print(f"\n[Curriculum] Epoch {self.current_epoch}: ì‹ ê·œ {len(new_indices):,}ê°œ + ë³µìŠµ {len(sampled_old_indices):,}ê°œ = ì´ {len(final_indices):,}ê°œ í•™ìŠµ")
        return iter(final_indices.tolist())

    def __len__(self):
        # __iter__ì™€ ë™ì¼í•œ ê°œìˆ˜ ê³„ì‚° ë¡œì§
        current_max = ((self.current_epoch + 1) / self.total_epochs) * 9
        prev_max = (self.current_epoch / self.total_epochs) * 9 if self.current_epoch > 0 else -1

        new_count = len(np.where((self.difficulties > prev_max) & (self.difficulties <= current_max))[0])
        old_count = len(np.where(self.difficulties <= prev_max)[0])

        return new_count + int(old_count * self.review_ratio)

"""# ë””ì½”ë”© í…ŒìŠ¤íŠ¸"""

tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
test_dataset = MultiHeadSoftDataset(train_df, tokenizer, MAX_LENGTH)

sample = test_dataset[0]

print("--- 1. Decoding Test ---")
decoded_text = tokenizer.decode(sample['input_ids'], skip_special_tokens=False)
print(f"Decoded (with special tokens):\n{decoded_text[:150]}...")

"""# ë ˆì´ë¸”ê³¼ ë‚œì´ë„ê°€ ì˜ ë“¤ì–´ê°”ëŠ”ì§€ í…ŒìŠ¤íŠ¸"""

print("\n--- 2. Label & Difficulty Test ---")
print(f"Label Tensor Shape: {sample['labels'].shape}")
print(f"Label Values: {sample['labels'].tolist()}")
print(f"Difficulty Score: {sample['difficulty'].item()}")

# ì›ë³¸ ë°ì´í„°ì™€ ëŒ€ì¡°
print(f"Original Row Difficulty: {train_df.iloc[0]['total_difficulty']}")

"""# *`ë°°ì¹˜ì‚¬ì´ì¦ˆ ì˜ ë‚˜ì™”ëŠ”ì§€ í…ŒìŠ¤íŠ¸`*"""

test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)
batch = next(iter(test_loader))

print("\n--- 3. Batch Shape Test ---")
print(f"Batch Input IDs Shape: {batch['input_ids'].shape}")
print(f"Batch Attention Mask Shape: {batch['attention_mask'].shape}")
print(f"Batch Labels Shape: {batch['labels'].shape}")
print(f"Batch Difficulty Shape: {batch['difficulty'].shape}")

"""# ëª¨ë¸ ì•„í‚¤í…ì²˜"""

import torch.nn as nn
from transformers import AutoModel

class MultiHeadModel(nn.Module):
    def __init__(self, model_name='klue/roberta-base', num_criteria=9):
        super().__init__()
        # 1. Shared Backbone: ë¬¸ë§¥ ì´í•´
        self.encoder = AutoModel.from_pretrained(model_name)
        self.hidden_size = self.encoder.config.hidden_size

        # 2. EDA ê¸°ë°˜ ê·¸ë£¹ ì •ì˜
        # Group A: Content, Group B: Safety, Group C: Coherence, Group D: Independent
        self.criteria = CRITERIA # 9ê°œ ì§€í‘œ ë¦¬ìŠ¤íŠ¸

        # 3. Task-Specific Heads: ê° ì§€í‘œë³„(9ê°œã…‹) ë…ë¦½ì ì¸ íŒë‹¨
        self.heads = nn.ModuleDict({
            criterion: nn.Sequential(
                nn.Linear(self.hidden_size, 256),
                nn.GELU(),
                nn.Dropout(0.1),
                nn.Linear(256, 1)
            ) for criterion in self.criteria
        })

    def forward(self, input_ids, attention_mask):
        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)
        cls_output = outputs.last_hidden_state[:, 0, :] # [CLS] í† í° í™œìš©

        # ê° í—¤ë“œì—ì„œ ê²°ê³¼ ì‚°ì¶œ
        logits = [self.heads[c](cls_output) for c in self.criteria]
        return torch.cat(logits, dim=-1) # [batch_size, 9]

"""# custom Multi-loss"""

import torch.nn.functional as F

class FocalLoss(nn.Module):
    """ë¶ˆê· í˜• ëŒ€ì‘ìš© Focal Loss (BCE í™•ì¥í˜•)"""
    def __init__(self, gamma=2.0, alpha=0.25):
        super().__init__()
        self.gamma = gamma
        self.alpha = alpha

    def forward(self, logits, targets):
        probs = torch.sigmoid(logits)
        bce_loss = F.binary_cross_entropy_with_logits(logits, targets, reduction='none')
        p_t = probs * targets + (1 - probs) * (1 - targets)
        loss = bce_loss * ((1 - p_t) ** self.gamma)

        if self.alpha >= 0:
            alpha_t = self.alpha * targets + (1 - self.alpha) * (1 - targets)
            loss = alpha_t * loss
        return loss

class AsymmetricLoss(nn.Module):
    """ê·¹ì‹¬í•œ ë¶ˆê· í˜• ëŒ€ì‘ìš© Asymmetric Loss (ASL)"""
    def __init__(self, gamma_neg=4, gamma_pos=0, clip=0.05):
        super().__init__()
        self.gamma_neg = gamma_neg
        self.gamma_pos = gamma_pos
        self.clip = clip

    def forward(self, logits, targets):
        probs = torch.sigmoid(logits)

        # Positive Loss
        loss_pos = targets * torch.log(probs + 1e-8) * ((1 - probs) ** self.gamma_pos)

        # Negative Loss (with clipping)
        p_neg = (probs + self.clip).clamp(max=1)
        loss_neg = (1 - targets) * torch.log(1 - probs + 1e-8) * (p_neg ** self.gamma_neg)

        return -(loss_pos + loss_neg)

class CombinedLoss(nn.Module):
    def __init__(self):
        super().__init__()
        # 1. ì§€ì¹¨ì— ë”°ë¥¸ Loss í•¨ìˆ˜ë“¤ ì¤€ë¹„
        self.bce = nn.BCEWithLogitsLoss(reduction='none')
        self.focal = FocalLoss(gamma=2.0)
        self.asl = AsymmetricLoss(gamma_neg=4)

        # 2. ê¸°ì¤€ë³„ ê°€ì¤‘ì¹˜ ì„¤ì • (EDA ì§€ì¹¨ 3.1 ì¤€ìˆ˜)
        self.weights = torch.tensor([
            1.0, # linguistic_acceptability -> Soft BCE
            1.2, # consistency -> BCE
            0.8, # interestingness -> ASL
            1.0, # unbias -> Focal
            1.0, # harmlessness -> BCE
            2.0, # no_hallucination -> Soft BCE
            0.8, # understandability -> Focal
            1.0, # sensibleness -> Soft BCE
            0.8  # specificity -> ASL
        ]).to(device)

    def forward(self, logits, targets):
        batch_size = logits.size(0)
        num_criteria = logits.size(1)

        # ê° ì§€í‘œë³„ë¡œ ê³„ì‚°ëœ Lossë¥¼ ë‹´ì„ ë¦¬ìŠ¤íŠ¸
        total_losses = []

        for i in range(num_criteria):
            crit_logits = logits[:, i]
            crit_targets = targets[:, i]

            # 3. ì§€í‘œë³„ ê¶Œì¥ Loss ë§¤í•‘
            if i in [0, 5, 7]: # Soft BCE ê·¸ë£¹
                loss = self.bce(crit_logits, crit_targets)
            elif i in [1, 4]:  # ì¼ë°˜ BCE ê·¸ë£¹
                loss = self.bce(crit_logits, crit_targets)
            elif i in [3, 6]:  # Focal Loss ê·¸ë£¹ (ë¶ˆê· í˜• ëŒ€ì‘)
                loss = self.focal(crit_logits, crit_targets)
            elif i in [2, 8]:  # ASL ê·¸ë£¹ (ê·¹ì‹¬í•œ ë¶ˆê· í˜• ëŒ€ì‘)
                loss = self.asl(crit_logits, crit_targets)

            # ê°€ì¤‘ì¹˜ ê³±í•˜ê¸°
            total_losses.append(loss * self.weights[i])

        # ëª¨ë“  ì§€í‘œì˜ Lossë¥¼ í•©ì‚° í›„ í‰ê· 
        combined_loss = torch.stack(total_losses).mean()
        return combined_loss

"""# í†µí•© í•™ìŠµ ë£¨í”„"""

from torch.optim import AdamW
from transformers import get_linear_schedule_with_warmup

# 1. ëª¨ë¸, ì†ì‹¤í•¨ìˆ˜, ë°ì´í„°ì…‹ ì¤€ë¹„
model = MultiHeadModel(MODEL_NAME).to(device)
criterion = CombinedLoss()
train_dataset = MultiHeadSoftDataset(train_df, tokenizer, MAX_LENGTH)
val_dataset = MultiHeadSoftDataset(val_df, tokenizer, MAX_LENGTH)

# 2. ìƒ˜í”ŒëŸ¬ ë° ë°ì´í„°ë¡œë” ì„¤ì •
train_sampler = CurriculumSampler(train_df, total_epochs=NUM_EPOCHS)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)

# 3. ì˜µí‹°ë§ˆì´ì € ë° ìŠ¤ì¼€ì¤„ëŸ¬ (í•™ìŠµë¥  ê´€ë¦¬)
optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)
total_steps = len(train_df) // BATCH_SIZE * NUM_EPOCHS # ì‹¤ì œëŠ” ìƒ˜í”ŒëŸ¬ ë•Œë¬¸ì— ë” ì ì§€ë§Œ ìµœëŒ€ì¹˜ë¡œ ì„¤ì •
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)

# 4. í•™ìŠµ ë£¨í”„ êµ¬í˜„
def train_model():
    for epoch in range(NUM_EPOCHS):
        # [Curriculum] ì—í­ ì„¤ì • ë° ë°ì´í„°ë¡œë” ê°±ì‹ 
        train_sampler.set_epoch(epoch)
        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=train_sampler)

        model.train()
        total_loss = 0

        for batch in tqdm(train_loader, desc=f"Epoch {epoch}"):
            optimizer.zero_grad()

            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            labels = batch['labels'].to(device)

            # Forward
            logits = model(input_ids, attention_mask)

            # Loss ê³„ì‚° (EDA ê°€ì¤‘ì¹˜ ë°˜ì˜ëœ CombinedLoss)
            loss = criterion(logits, labels)

            loss.backward()
            optimizer.step()
            scheduler.step()

            total_loss += loss.item()

        avg_loss = total_loss / len(train_loader)
        print(f"Epoch {epoch} Average Loss: {avg_loss:.4f}")

"""# í‰ê¸°ì§€í‘œ ê³„ì‚°"""

from sklearn.metrics import f1_score

def calculate_metrics(logits, labels):
    preds = (torch.sigmoid(logits) > 0.5).float().cpu().numpy()
    labels = (labels > 0.5).float().cpu().numpy()

    f1_list = []
    acc_list = [] # ì •í™•ë„ë¥¼ ë‹´ì„ ë°”êµ¬ë‹ˆ ì¶”ê°€

    for i in range(len(CRITERIA)):
        # 1. F1 Score ê³„ì‚°
        f1 = f1_score(labels[:, i], preds[:, i], average='macro', zero_division=0)
        f1_list.append(f1)

        # 2. Accuracy(ì •í™•ë„) ê³„ì‚°: ë§íŒ ê°œìˆ˜ / ì „ì²´ ê°œìˆ˜
        acc = (labels[:, i] == preds[:, i]).mean()
        acc_list.append(acc)

    # í‰ê·  F1, ìƒì„¸ F1 ë¦¬ìŠ¤íŠ¸, ìƒì„¸ ì •í™•ë„ ë¦¬ìŠ¤íŠ¸ 3ê°œë¥¼ ëŒë ¤ì¤€ë‹¤
    return np.mean(f1_list), f1_list, acc_list

# small_train_df = train_df.sample(n=100000, random_state=SEED).reset_index(drop=True)
# small_val_df = val_df.sample(n=20000, random_state=SEED).reset_index(drop=True)

# # ìƒ˜í”Œìš© ë°ì´í„°ì…‹ê³¼ ìƒ˜í”ŒëŸ¬ ë‹¤ì‹œ ë§Œë“¤ê¸°
# small_train_dataset = MultiHeadSoftDataset(small_train_df, tokenizer, MAX_LENGTH)
# small_val_dataset = MultiHeadSoftDataset(small_val_df, tokenizer, MAX_LENGTH)
# small_train_sampler = CurriculumSampler(small_train_df, total_epochs=NUM_EPOCHS)

"""ìƒ˜í”Œë§"""

print("--- [í•™ìŠµ ë°ì´í„° ë‚œì´ë„ë³„ ìƒì„¸ ë¶„í¬] ---")
# 1. ê° ì ìˆ˜ë³„ ì •í™•í•œ ê°œìˆ˜
diff_counts = train_df['total_difficulty'].value_counts().sort_index()
print(diff_counts)

print("\n--- [ì—í­ë³„ í•™ìŠµí•˜ê²Œ ë  ë°ì´í„° ì–‘ ì˜ˆì¸¡] ---")
total_n = len(train_df)
for i in range(10): # 0ì ë¶€í„° 9ì ê¹Œì§€
    count = len(train_df[train_df['total_difficulty'] <= i])
    percentage = (count / total_n) * 100
    print(f"ë‚œì´ë„ {i} ì´í•˜ (ëˆ„ì ): {count:>7,}ê°œ | ì „ì²´ì˜ {percentage:>6.2f}%")

# ì—í­ 0ì˜ ê¸°ì¤€ì¸ 3.0ì  í™•ì¸
epoch_0_limit = 3.0
epoch_0_count = len(train_df[train_df['total_difficulty'] <= epoch_0_limit])
print(f"\nğŸ’¡ ì—í­ 0 (ë‚œì´ë„ {epoch_0_limit} ì´í•˜) ì‹¤ì œ í•™ìŠµëŸ‰: {epoch_0_count:,}ê°œ")

from torch.optim import AdamW
from transformers import get_linear_schedule_with_warmup

# --- [ì¤€ë¹„ ë‹¨ê³„] ëª¨ë¸ ë° ë„êµ¬ ì´ˆê¸°í™” ---
model = MultiHeadModel(MODEL_NAME).to(device)
criterion = CombinedLoss()
optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)

# ë°ì´í„°ì…‹ ë° ìƒ˜í”ŒëŸ¬ ì¤€ë¹„
train_dataset = MultiHeadSoftDataset(train_df, tokenizer, MAX_LENGTH)
val_dataset = MultiHeadSoftDataset(val_df, tokenizer, MAX_LENGTH)
train_sampler = CurriculumSampler(train_df, total_epochs=NUM_EPOCHS)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)

# --- [í•¨ìˆ˜ ì •ì˜] í•™ìŠµ ë° ê²€ì¦ ì—”ì§„ ---
def train_and_eval(model, criterion, optimizer, train_dataset, val_dataset, train_sampler):
    # ê·¸ë˜í”„ë¥¼ ê·¸ë¦¬ê¸° ìœ„í•œ ê¸°ë¡ ë°”êµ¬ë‹ˆ
    history = {'loss': [], 'f1': []}

    for epoch in range(NUM_EPOCHS):
        # [Curriculum] ì—í­ ì„¤ì • ë° ë°ì´í„°ë¡œë” ë™ì  ìƒì„±
        train_sampler.set_epoch(epoch)
        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=train_sampler)

        # [A] í•™ìŠµ ë‹¨ê³„ (Training)
        model.train()
        epoch_loss = 0

        for batch in tqdm(train_loader, desc=f"Epoch {epoch} Training"):
            optimizer.zero_grad()

            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            labels = batch['labels'].to(device)

            logits = model(input_ids, attention_mask)
            loss = criterion(logits, labels)

            loss.backward()
            optimizer.step()

            epoch_loss += loss.item()

        avg_loss = epoch_loss / len(train_loader)
        history['loss'].append(avg_loss)

        # [B] ê²€ì¦ ë‹¨ê³„ (Validation)
        model.eval()
        all_logits = []
        all_labels = []

        with torch.no_grad():
            for batch in val_loader:
                logits = model(batch['input_ids'].to(device), batch['attention_mask'].to(device))
                all_logits.append(logits.cpu()) # ë©”ëª¨ë¦¬ ê´€ë¦¬ë¥¼ ìœ„í•´ cpuë¡œ ì´ë™
                all_labels.append(batch['labels'].cpu())

        # 9ê°œ ì§€í‘œì˜ ìƒì„¸ ì„±ì í‘œ ê³„ì‚°
        all_logits = torch.cat(all_logits, dim=0)
        all_labels = torch.cat(all_labels, dim=0)

        # ì•ì„œ ë§Œë“  ì±„ì ê¸° í˜¸ì¶œ
        mean_f1, f1_list, acc_list = calculate_metrics(all_logits, all_labels)
        history['f1'].append(mean_f1)

        # --- ìƒì„¸ ì„±ì í‘œ ì¶œë ¥ ---
        print(f"\n" + "="*50)
        print(f"[Epoch {epoch}] ìƒì„¸ ì„±ì í‘œ")
        print("-" * 50)
        for i, criterion_name in enumerate(CRITERIA):
            print(f"{criterion_name:25}: F1={f1_list[i]:.4f} | Acc={acc_list[i]:.2%}")
        print("-" * 50)
        print(f"ì „ì²´ í‰ê·  F1: {mean_f1:.4f} | Loss: {avg_loss:.4f}")
        print("="*50 + "\n")

    return history # í•™ìŠµ ê¸°ë¡ ë°˜í™˜

# ì‘ì€ ë°ì´í„°ë¡œ ì—”ì§„ ê°€ë™ í…ŒìŠ¤íŠ¸
print("---ì° í•™ìŠµ ì‹œì‘ ---")
# --- [ì‹¤í–‰]

history = train_and_eval(
    model,
    criterion,
    optimizer,
    train_dataset,
    val_dataset,
    train_sampler
)

# 1. ë“œë¼ì´ë¸Œ ë‚´ ì €ì¥ í´ë” ìƒì„±
import os
save_dir = '/content/drive/MyDrive/ai_í—ˆë¸Œ_ë°ì´í„°ì…‹'
if not os.path.exists(save_dir):
    os.makedirs(save_dir)

# 2. ëª¨ë¸ ê°€ì¤‘ì¹˜ ì €ì¥ (ê°€ì¥ ì¤‘ìš”!)
torch.save(model.state_dict(), os.path.join(save_dir, 'model_weights.pt'))

# 3. í† í¬ë‚˜ì´ì € ì €ì¥
tokenizer.save_pretrained(save_dir)

print(f"êµ¬ê¸€ ë“œë¼ì´ë¸Œì— ì €ì¥ ì™„ë£Œ: {save_dir}")

# 1. ëª¨ë¸ ê°ì²´ ìƒˆë¡œ ìƒì„±
import os
model = MultiHeadModel(MODEL_NAME).to(device)

# 2. ì €ì¥ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ
save_dir = '/content/drive/MyDrive/ai_í—ˆë¸Œ_ë°ì´í„°ì…‹'
model.load_state_dict(torch.load(os.path.join(save_dir, 'model_weights.pt')))

# 3. í† í¬ë‚˜ì´ì € ë¡œë“œ
tokenizer = AutoTokenizer.from_pretrained(save_dir)

# 4. ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì „í™˜
model.eval()

print("âœ… í•™ìŠµëœ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")

# ê²€ì¦ ë‹¨ê³„ (Validation) ë¡œì§ë§Œ ì‹¤í–‰
all_logits = []
all_labels = []

print("ê²€ì¦ ë°ì´í„° í‰ê°€ ì¤‘...")
with torch.no_grad():
    for batch in tqdm(val_loader, desc="Evaluating"):
        logits = model(batch['input_ids'].to(device), batch['attention_mask'].to(device))
        all_logits.append(logits.cpu())
        all_labels.append(batch['labels'].cpu())

# ì„±ì í‘œ ê³„ì‚°
all_logits = torch.cat(all_logits, dim=0)
all_labels = torch.cat(all_labels, dim=0)
mean_f1, f1_list, acc_list = calculate_metrics(all_logits, all_labels)

# --- ìƒì„¸ ì„±ì í‘œ ì¶œë ¥ ---
print(f"\n" + "="*50)
print(f"[ë¶ˆëŸ¬ì˜¨ ëª¨ë¸] ìµœì¢… ê²€ì¦ ì„±ì í‘œ")
print("-" * 50)
for i, criterion_name in enumerate(CRITERIA):
    print(f"{criterion_name:25}: F1={f1_list[i]:.4f} | Acc={acc_list[i]:.2%}")
print("-" * 50)
print(f"ì „ì²´ í‰ê·  F1: {mean_f1:.4f}")
print("="*50 + "\n")

def predict_detailed(question, response, model, tokenizer):
    model.eval()
    # 1. ì…ë ¥ í…ìŠ¤íŠ¸ ê²°í•© (í•™ìŠµ ë•Œì™€ ë™ì¼í•œ í¬ë§·)
    input_text = f"{question} [SEP] {response}"

    # 2. í† í°í™” ë° GPU ì´ë™
    inputs = tokenizer(
        input_text,
        return_tensors='pt',
        padding='max_length',
        truncation=True,
        max_length=MAX_LENGTH
    ).to(device)

    # 3. ëª¨ë¸ ì¶”ë¡ 
    with torch.no_grad():
        logits = model(inputs['input_ids'], inputs['attention_mask'])
        # í™•ë¥ ë¡œ ë³€í™˜ (0~1 ì‚¬ì´ ì†Œìˆ˜ì )
        probs = torch.sigmoid(logits).cpu().numpy()[0]
        # 0.5 ê¸°ì¤€ìœ¼ë¡œ í•©ê²©(1)/ë¶ˆí•©ê²©(0) íŒì •
        preds = (probs > 0.5).astype(int)

    # 4. ê²°ê³¼ ì¶œë ¥ (ë² ì´ìŠ¤ ì½”ë“œ ìŠ¤íƒ€ì¼)
    print(f"\n" + "="*50)
    print(f"   [ AI í’ˆì§ˆ í‰ê°€ ìƒì„¸ ì¶”ë¡  ê²°ê³¼ ]")
    print("="*50)
    print(f"ì§ˆë¬¸: {question}")
    print(f"ì‘ë‹µ: {response}")
    print("-" * 50)
    print(f"{'í‰ê°€ í•­ëª©':<25} | {'ê²°ê³¼':<5} | {'í™•ì‹ ë„'}")
    print("-" * 50)

    for i, criterion in enumerate(CRITERIA):
        status = "âœ… PASS" if preds[i] == 1 else "âŒ FAIL"
        # í™•ì‹ ë„ê°€ ë†’ì„ìˆ˜ë¡ ëª¨ë¸ì´ í•´ë‹¹ ê²°ê³¼ì— ìì‹ ìˆì–´ í•¨
        confidence = probs[i] if preds[i] == 1 else (1 - probs[i])
        print(f"{criterion:<25} | {status:<5} | {probs[i]:.2%}")
    print("="*50 + "\n")

# --- í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì˜ˆì‹œ ---
q_test = "í•œêµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì•¼?"
r_test = "í•œêµ­ì˜ ìˆ˜ë„ëŠ” ë©•ì‹œì½”ì…ë‹ˆë‹¤"

predict_detailed(q_test, r_test, model, tokenizer)