# -*- coding: utf-8 -*-
"""Test.ipynbì˜ ì‚¬ë³¸

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uAQBhJcYvh91cqbUO04Hkoy5rKHrSvnW

# AI í’ˆì§ˆ í‰ê°€ ëª¨ë¸ í•™ìŠµ - klue/roberta-base

ì´ ë…¸íŠ¸ë¶ì€ AI ì‘ë‹µ í’ˆì§ˆ í‰ê°€ë¥¼ ìœ„í•œ Multi-label Classification ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤.

**í‰ê°€ ê¸°ì¤€ (9ê°œ)**:

- linguistic_acceptability (ì–¸ì–´ì  ìˆ˜ìš©ì„±)
- consistency (ì¼ê´€ì„±)
- interestingness (í¥ë¯¸ë¡œì›€)
- unbias (í¸í–¥ ì—†ìŒ)
- harmlessness (ë¬´í•´ì„±)
- no_hallucination (í™˜ê° ì—†ìŒ)
- understandability (ì´í•´ ê°€ëŠ¥ì„±)
- sensibleness (í•©ë¦¬ì„±)
- specificity (êµ¬ì²´ì„±)

## 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° ì„í¬íŠ¸
"""

from google.colab import drive
drive.mount('/content/drive/')

import pandas as pd
import numpy as np
import torch
from torch.utils.data import Dataset, DataLoader
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    TrainingArguments,
    Trainer,
)
from sklearn.metrics import accuracy_score, f1_score, classification_report
from tqdm.auto import tqdm
import warnings

warnings.filterwarnings('ignore')

# GPU í™•ì¸
device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')
print(f"Using device: {device}")

"""## 2. ì„¤ì •"""

# ëª¨ë¸ ë° í•™ìŠµ ì„¤ì •
MODEL_NAME = "klue/roberta-base"
MAX_LENGTH = 330
BATCH_SIZE = 128
LEARNING_RATE = 2e-5
NUM_EPOCHS = 3
SEED = 42

# í‰ê°€ ê¸°ì¤€ (íƒ€ê²Ÿ ì»¬ëŸ¼)
CRITERIA = [
    'linguistic_acceptability',
    'consistency',
    'interestingness',
    'unbias',
    'harmlessness',
    'no_hallucination',
    'understandability',
    'sensibleness',
    'specificity'
]
NUM_LABELS = len(CRITERIA)

# ì‹œë“œ ê³ ì •
torch.manual_seed(SEED)
np.random.seed(SEED)

"""## 3. ë°ì´í„° ë¡œë“œ"""

# # unzip
# unzip_path = '/content/drive/MyDrive/AI_data/data.zip'
# !unzip -qq {unzip_path} -d /content/drive/MyDrive/AI_data/

# Training ë° Validation ë°ì´í„° ë¡œë“œ (aggregated ë²„ì „ ì‚¬ìš© - majority voting ê²°ê³¼)
train_df = pd.read_csv('/content/drive/MyDrive/AI_data/data/train/training_all_aggregated.csv', encoding='utf-8-sig')
val_df = pd.read_csv('/content/drive/MyDrive/AI_data/data/val/validation_all_aggregated.csv', encoding='utf-8-sig')

print(f"Training ë°ì´í„°: {len(train_df):,}ê°œ")
print(f"Validation ë°ì´í„°: {len(val_df):,}ê°œ")

train_df['topic'].value_counts()

# ë°ì´í„° í™•ì¸
train_df[train_df['topic']=='ì—”í„°í…Œì¸ë¨¼íŠ¸, ì˜¤ë½, ì˜ˆìˆ '].head(10)

# 1. ì§€í‘œ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ ìƒì„± (ì»¬ëŸ¼ëª…: í•œê¸€ ì„¤ëª…)
quality_metrics = {
    "linguistic_acceptability_majority": "ì–¸ì–´í•™ì  ìˆ˜ìš©ì„±",
    "consistency_majority": "ì¼ê´€ì„±",
    "interestingness_majority": "í¥ë¯¸ì„±",
    "unbias_majority": "ë¹„í¸í–¥ì„±",
    "harmlessness_majority": "ë¬´í•´ì„±",
    "no_hallucination_majority": "ì •ë³´ ê·¼ê±°ì„±",
    "understandability_majority": "ì´í•´ ê°€ëŠ¥ì„±",
    "sensibleness_majority": "ë‹µë³€ì˜ ì ì ˆì„±",
    "specificity_majority": "ë‹µë³€ì˜ êµ¬ì²´ì„±"
}

target_topic = 'ì—”í„°í…Œì¸ë¨¼íŠ¸, ì˜¤ë½, ì˜ˆìˆ '
entertainment_df = train_df[train_df['topic'] == target_topic]

for i, row in entertainment_df.tail(5).iterrows():
    print(f"[{i+1}ë²ˆ ë°ì´í„°]")
    print(f"ğŸ™‹ ì§ˆë¬¸: {row['human_question']}")
    print(f"ğŸ¤– ì‘ë‹µ: {row['bot_response']}")
    print("\n[ğŸ“Š í’ˆì§ˆ í‰ê°€ ìƒì„¸]")

    # 9ê°€ì§€ ì§€í‘œë¥¼ ìˆœíšŒí•˜ë©° ì¶œë ¥
    for col, name in quality_metrics.items():
        status = "âœ… Pass" if row[col] == 1 else "âŒ Fail"
        print(f" - {name}: {status}")

    print("-" * 50)

# ì»¬ëŸ¼ í™•ì¸
print("ì»¬ëŸ¼ ëª©ë¡:")
print(train_df.columns.tolist())

def create_hard_negatives(df, negative_ratio=0.2, seed=42):
    """ê¸°ì¡´ ë°ì´í„°ì˜ ë‹µë³€ì„ ì„ì–´ 'ë‚´ìš©ì´ í‹€ë¦°' ë¶€ì • ìƒ˜í”Œì„ ìƒì„±í•©ë‹ˆë‹¤."""
    n_samples = int(len(df) * negative_ratio)
    neg_df = df.sample(n=n_samples, random_state=seed).copy()

    # ë‹¤ë¥¸ í–‰ì˜ ë‹µë³€ì„ ë¬´ì‘ìœ„ë¡œ ê°€ì ¸ì™€ ë§¤ì¹­ (ë‚´ìš© ë¶ˆì¼ì¹˜ ìœ ë„)
    shuffled_responses = df.sample(n=n_samples, random_state=seed+1)['bot_response'].values
    neg_df['bot_response'] = shuffled_responses

    # ëª¨ë“  í’ˆì§ˆ ì§€í‘œ ë¼ë²¨ì„ 0(Fail)ìœ¼ë¡œ ì„¤ì •
    for criterion in CRITERIA:
        neg_df[f"{criterion}_majority"] = 0

    print(f"âœ… {n_samples}ê°œì˜ Hard Negative ë°ì´í„° ìƒì„± ì™„ë£Œ!")
    return neg_df

import pandas as pd
from tqdm import tqdm
import numpy as np # ğŸ†• ì¶”ê°€ (ëœë¤ ì‹œë“œ ë“±ì„ ìœ„í•´ í•„ìš”)

# 1. ê¸°ì¡´ í•¨ìˆ˜ ìœ ì§€
def merge_dialogue_context(df, window_size=2):

    df = df.sort_values(['conversation_id', 'utterance_index']).reset_index(drop=True)
    contexts = []
    for i in tqdm(range(len(df)), desc="Merging Contexts"):
        current_row = df.iloc[i]
        c_id = current_row['conversation_id']
        history = df[(df['conversation_id'] == c_id) & (df.index < i)].tail(window_size)
        history_text = ""
        for _, h_row in history.iterrows():
            history_text += f"{h_row['human_question']} [SEP] {h_row['bot_response']} [SEP] "
        full_input = f"{history_text}{current_row['human_question']} [SEP] {current_row['bot_response']}"
        contexts.append(full_input)
    df['input_with_context'] = contexts
    return df

# 2. ğŸ†• [í•¨ìˆ˜ ì¶”ê°€] Hard Negative ìƒì„± í•¨ìˆ˜
def create_hard_negatives(df, negative_ratio=0.2, seed=42):
    """ê¸°ì¡´ ë°ì´í„°ì˜ ë‹µë³€ì„ ì„ì–´ 'ë‚´ìš©ì´ í‹€ë¦°' ë¶€ì • ìƒ˜í”Œì„ ìƒì„±í•©ë‹ˆë‹¤."""
    n_samples = int(len(df) * negative_ratio)
    neg_df = df.sample(n=n_samples, random_state=seed).copy()

    # ë‹¤ë¥¸ í–‰ì˜ ë‹µë³€ì„ ë¬´ì‘ìœ„ë¡œ ê°€ì ¸ì™€ ë§¤ì¹­ (ë‚´ìš© ë¶ˆì¼ì¹˜ ìœ ë„)
    shuffled_responses = df.sample(n=n_samples, random_state=seed+1)['bot_response'].values
    neg_df['bot_response'] = shuffled_responses

    # ëª¨ë“  í’ˆì§ˆ ì§€í‘œ ë¼ë²¨ì„ 0(Fail)ìœ¼ë¡œ ì„¤ì •
    for criterion in CRITERIA:
        neg_df[criterion] = 0
    return neg_df

# --- ì ìš©í•˜ê¸° ---

# [ë³€ê²½ í¬ì¸íŠ¸ 1] í•™ìŠµ ë°ì´í„° í™•ì¥
print("ğŸ› ï¸ Hard Negative ë°ì´í„° ìƒì„± ë° í•™ìŠµ ë°ì´í„° í™•ì¥ ì¤‘...")
hard_neg_df = create_hard_negatives(train_df, negative_ratio=0.2)
# ê¸°ì¡´ train_dfì™€ ìƒì„±ëœ ë¶€ì • ë°ì´í„°ë¥¼ í•©ì¹©ë‹ˆë‹¤.
extended_train_df = pd.concat([train_df, hard_neg_df], axis=0, ignore_index=True)

# [ë³€ê²½ í¬ì¸íŠ¸ 2] í™•ì¥ëœ ë°ì´í„°ì…‹(extended_train_df)ìœ¼ë¡œ ë§¥ë½ ë³‘í•© ì‹¤í–‰
print("í•™ìŠµ ë°ì´í„° ë§¥ë½ ë³‘í•© ì¤‘ (ë¶€ì • ìƒ˜í”Œ í¬í•¨)...")
train_df = merge_dialogue_context(extended_train_df, window_size=2)

# ê²€ì¦ ë°ì´í„°ëŠ” ì›ë³¸ ê·¸ëŒ€ë¡œ ìœ ì§€ (í‰ê°€ì˜ ê°ê´€ì„±ì„ ìœ„í•´)
print("ê²€ì¦ ë°ì´í„° ë§¥ë½ ë³‘í•© ì¤‘...")
val_df = merge_dialogue_context(val_df, window_size=2)

"""## 4. ë°ì´í„° ì „ì²˜ë¦¬"""

def preprocess_data(df: pd.DataFrame) -> pd.DataFrame:
    """ë°ì´í„° ì „ì²˜ë¦¬: ì…ë ¥ í…ìŠ¤íŠ¸ ìƒì„± ë° ê²°ì¸¡ì¹˜ ì²˜ë¦¬"""
    df = df.copy()

    # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
    df['human_question'] = df['human_question'].fillna('')
    df['bot_response'] = df['bot_response'].fillna('')

    # ì…ë ¥ í…ìŠ¤íŠ¸ ìƒì„±: [ì§ˆë¬¸] + [SEP] + [ì‘ë‹µ]
    df['input_text'] = df['human_question'] + ' [SEP] ' + df['bot_response']

    # íƒ€ê²Ÿ ì»¬ëŸ¼ ì¶”ì¶œ (majority voting ê²°ê³¼)
    # ê²°ê³¼ê°€ [1, 1, 0, 1, 0, 0, 1, 1, 1] ê³¼ ê°™ì€ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ì €ì¥ë¨
    target_cols = [f'{c}_majority' for c in CRITERIA]

    # íƒ€ê²Ÿ ê²°ì¸¡ì¹˜ ì œê±°
    df = df.dropna(subset=target_cols)

    return df

train_df = preprocess_data(train_df)
val_df = preprocess_data(val_df)

print(f"ì „ì²˜ë¦¬ í›„ Training ë°ì´í„°: {len(train_df):,}ê°œ")
print(f"ì „ì²˜ë¦¬ í›„ Validation ë°ì´í„°: {len(val_df):,}ê°œ")

# ë ˆì´ë¸” ë¶„í¬ í™•ì¸
target_cols = [f'{c}_majority' for c in CRITERIA]

print("=" * 50)
print("ë ˆì´ë¸” ë¶„í¬ (Training)")
print("=" * 50)
for col in target_cols:
    pos_ratio = train_df[col].mean()
    print(f"{col}: {pos_ratio:.2%} positive")

"""## 5. Tokenizer ë¡œë“œ"""

# klue/roberta-base í† í¬ë‚˜ì´ì € ë¡œë“œ
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)

print(f"Tokenizer ë¡œë“œ ì™„ë£Œ: {MODEL_NAME}")
print(f"Vocab size: {tokenizer.vocab_size:,}")

# í† í¬ë‚˜ì´ì € í…ŒìŠ¤íŠ¸
sample_text = train_df['input_with_context'].iloc[0]
print(f"ìƒ˜í”Œ í…ìŠ¤íŠ¸:\n{sample_text}\n")

tokens = tokenizer(sample_text, truncation=True, max_length=MAX_LENGTH)
print(f"í† í° ìˆ˜: {len(tokens['input_ids'])}")

# 1. ìƒˆë¡œìš´ 'input_with_context' ê¸°ì¤€ í† í° ê¸¸ì´ ê³„ì‚°
token_lengths = [len(tokenizer.encode(text, add_special_tokens=True)) for text in tqdm(train_df['input_with_context'], desc="Checking New Lengths")]

# 2. í†µê³„ì¹˜ í™•ì¸
print(f"\n[ğŸ“Š ë§¥ë½ í¬í•¨ í† í° í†µê³„]")
print(f" - 95th percentile: {np.percentile(token_lengths, 95)}")
print(f" - 99th percentile: {np.percentile(token_lengths, 99)}")
print(f" - ìµœëŒ€ ê¸¸ì´: {np.max(token_lengths)}")

# 3. ë°ì´í„° ì €ì¥ (ë‚´ì¼ ë°”ë¡œ ë¶ˆëŸ¬ì™€ì„œ ì“¸ ìˆ˜ ìˆê²Œ)
# êµ¬ê¸€ ë“œë¼ì´ë¸Œ ê²½ë¡œë¡œ ì„¤ì •í•˜ì„¸ìš”.
train_df.to_csv('/content/drive/MyDrive/final_train_context.csv', index=False)
val_df.to_csv('/content/drive/MyDrive/final_val_context.csv', index=False)
print("\nâœ… ìµœì¢… ë°ì´í„°ì…‹ ì €ì¥ ì™„ë£Œ!")

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm

# 1. ëª¨ë“  input_textì˜ í† í° ê¸¸ì´ ê³„ì‚° (ì‹œê°„ì´ ì¡°ê¸ˆ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)
token_lengths = [len(tokenizer.encode(text, add_special_tokens=True)) for text in tqdm(train_df['input_with_context'], desc="Calculating lengths")]

# 2. í†µê³„ì¹˜ ê³„ì‚°
max_len = np.max(token_lengths)
mean_len = np.mean(token_lengths)
p95 = np.percentile(token_lengths, 95)
p99 = np.percentile(token_lengths, 99)

print(f"\n[ğŸ“Š Token Length Statistics]")
print(f" - ì „ì²´ ë°ì´í„° ìˆ˜: {len(token_lengths)}ê°œ")
print(f" - ìµœëŒ€ í† í° ê¸¸ì´: {max_len}")
print(f" - í‰ê·  í† í° ê¸¸ì´: {mean_len:.2f}")
print(f" - 95% ë°ì´í„°ê°€ í¬í•¨ë˜ëŠ” ê¸¸ì´: {p95}")
print(f" - 99% ë°ì´í„°ê°€ í¬í•¨ë˜ëŠ” ê¸¸ì´: {p99}")

# 3. ë¶„í¬ ì‹œê°í™”
plt.figure(figsize=(12, 6))
sns.histplot(token_lengths, bins=50, color='teal', kde=True)
plt.axvline(p95, color='orange', linestyle='--', label=f'95th Percentile ({p95:.0f})')
plt.axvline(p99, color='red', linestyle='--', label=f'99th Percentile ({p99:.0f})')
plt.title('Token Length Distribution (Question + Answer)')
plt.xlabel('Number of Tokens')
plt.ylabel('Count')
plt.legend()
plt.show()

"""## 6. Dataset í´ë˜ìŠ¤ ì •ì˜"""

class QualityEvalDataset(Dataset):
    """AI í’ˆì§ˆ í‰ê°€ ë°ì´í„°ì…‹"""

    def __init__(self, df: pd.DataFrame, tokenizer, max_length: int = 330):
        self.df = df.reset_index(drop=True)
        self.tokenizer = tokenizer
        self.max_length = max_length
        self.target_cols = [f'{c}_majority' for c in CRITERIA]

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        text = row['input_with_context']
        labels = row[self.target_cols].values.astype(np.float32)

        # í† í¬ë‚˜ì´ì¦ˆ
        encoding = self.tokenizer(
            text,
            truncation=True,
            max_length=self.max_length,
            padding='max_length',
            return_tensors='pt'
        )

        return {
            'input_ids': encoding['input_ids'].squeeze(0),
            'attention_mask': encoding['attention_mask'].squeeze(0),
            'labels': torch.tensor(labels, dtype=torch.float)
        }

# Dataset ìƒì„±
train_dataset = QualityEvalDataset(train_df, tokenizer, MAX_LENGTH)
val_dataset = QualityEvalDataset(val_df, tokenizer, MAX_LENGTH)

print(f"Train dataset size: {len(train_dataset):,}")
print(f"Val dataset size: {len(val_dataset):,}")

# Dataset í™•ì¸
sample = train_dataset[0]
print(f"input_ids shape: {sample['input_ids'].shape}")
print(f"attention_mask shape: {sample['attention_mask'].shape}")
print(f"labels shape: {sample['labels'].shape}")
print(f"labels: {sample['labels']}")

"""## 7. ëª¨ë¸ ë¡œë“œ"""

# Multi-label Classificationì„ ìœ„í•œ ëª¨ë¸ ë¡œë“œ
model = AutoModelForSequenceClassification.from_pretrained(
    MODEL_NAME,
    num_labels=NUM_LABELS,
    problem_type="multi_label_classification"
)

model.to(device)
print(f"ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {MODEL_NAME}")
print(f"íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in model.parameters()):,}")

"""## 8. í‰ê°€ ì§€í‘œ í•¨ìˆ˜"""

def compute_metrics(eval_pred):
    """í‰ê°€ ì§€í‘œ ê³„ì‚° (ìˆ˜ì • ì™„ë£Œ ë²„ì „)"""
    predictions, labels = eval_pred

    # 1. Sigmoid ì ìš© í›„ 0.5 ê¸°ì¤€ìœ¼ë¡œ ì´ì§„í™”
    # ì˜ˆì¸¡ê°’(logits)ì„ í™•ë¥ ë¡œ ë³€í™˜í•˜ê³  0 ë˜ëŠ” 1ë¡œ ê²°ì •í•©ë‹ˆë‹¤.
    predictions = torch.sigmoid(torch.tensor(predictions)).numpy()
    predictions = (predictions > 0.5).astype(int)
    labels = labels.astype(int)

    # 2. ê³µí†µ ì§€í‘œ ê³„ì‚°
    # ì „ì²´ ì •í™•ë„: 9ê°œ ì§€í‘œê°€ ëª¨ë‘ ì¼ì¹˜í•´ì•¼ 1ì 
    exact_match = np.all(predictions == labels, axis=1).mean()
    # ì „ì²´ì ì¸ ê· í˜•ì„ ë³´ëŠ” Micro/Macro F1
    micro_f1 = f1_score(labels, predictions, average='micro')
    macro_f1 = f1_score(labels, predictions, average='macro')

    metrics = {
        'exact_match': exact_match,
        'micro_f1': micro_f1,
        'macro_f1': macro_f1,
    }

    # 3. ê° ê¸°ì¤€(Criterion)ë³„ ì„¸ë¶€ ì§€í‘œ ê³„ì‚° (í•˜ë‚˜ì˜ ë£¨í”„ì—ì„œ ì²˜ë¦¬)
    # ê°€ì´ë“œë¼ì¸ì— ë”°ë¼ ì •í™•ë„(acc)ì™€ F1-scoreë¥¼ ëª¨ë‘ ê¸°ë¡í•©ë‹ˆë‹¤.
    for i, criterion in enumerate(CRITERIA):
        # í•´ë‹¹ ì§€í‘œ ì—´ë§Œ ì¶”ì¶œ
        pred_col = predictions[:, i]
        label_col = labels[:, i]

        # ê¸°ì¤€ë³„ ì •í™•ë„
        metrics[f'{criterion}_acc'] = (pred_col == label_col).mean()
        # ê¸°ì¤€ë³„ F1 (ë°ì´í„° ë¶ˆê· í˜• ê³ ë ¤)
        metrics[f'{criterion}_f1'] = f1_score(label_col, pred_col, zero_division=0)

    return metrics

"""## 9. Trainer ì„¤ì • ë° í•™ìŠµ"""

# Training Arguments ì„¤ì •
training_args = TrainingArguments(
    output_dir='./outputs/klue-roberta-base',
    num_train_epochs=NUM_EPOCHS,
    per_device_train_batch_size=BATCH_SIZE,
    per_device_eval_batch_size=BATCH_SIZE * 2,
    learning_rate=LEARNING_RATE,
    weight_decay=0.01,
    warmup_ratio=0.1,
    logging_dir='./logs',
    logging_steps=100,
    eval_strategy='epoch',
    save_strategy='epoch',
    load_best_model_at_end=True,
    metric_for_best_model='macro_f1',
    greater_is_better=True,
    report_to='none',  # wandb ì‚¬ìš© ì‹œ 'wandb'ë¡œ ë³€ê²½
    seed=SEED,
    fp16=torch.cuda.is_available(),  # CUDA ì‚¬ìš© ì‹œ FP16 í™œì„±í™”
)

# Trainer ìƒì„±
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    compute_metrics=compute_metrics,
)

# --- Step 3: ë°ì´í„°ì…‹ ë° Trainer ê°±ì‹  ---

# 1. Datasetì„ ë°˜ë“œì‹œ ë‹¤ì‹œ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤ (ê°€ì¥ ì¤‘ìš”!)
# ì´ ì½”ë“œê°€ ì‹¤í–‰ë˜ì–´ì•¼ 'hard_neg_df'ê°€ í•©ì³ì§„ 'train_df'ê°€ ëª¨ë¸ì˜ ì…ë ¥ ë°ì´í„°ì…‹ìœ¼ë¡œ ë³€í™˜ë©ë‹ˆë‹¤.
train_dataset = QualityEvalDataset(train_df, tokenizer, MAX_LENGTH)
val_dataset = QualityEvalDataset(val_df, tokenizer, MAX_LENGTH)

# 2. [ì„ íƒì‚¬í•­] TrainingArguments ìˆ˜ì • (ê·¸ëŒ€ë¡œ ì¨ë„ ë˜ì§€ë§Œ ì¶”ì²œ ì„¤ì •)
# ë°ì´í„°ê°€ ëŠ˜ì–´ë‚¬ìœ¼ë¯€ë¡œ, ê¸°ì¡´ë³´ë‹¤ ì¡°ê¸ˆ ë” ì¡°ì‹¬ìŠ¤ëŸ½ê²Œ í•™ìŠµí•˜ë„ë¡ lrì„ ì‚´ì§ ë‚®ì¶œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
training_args.learning_rate = 1e-5  # ì˜ˆ: 2e-5ì—ì„œ 1e-5ë¡œ í•˜í–¥ (ì„ íƒì‚¬í•­)
training_args.num_train_epochs = 3 # ì—í¬í¬ ìˆ˜ëŠ” ìœ ì§€í•˜ê±°ë‚˜ ìƒí™©ì— ë§ê²Œ ì¡°ì ˆ

# 3. Trainer ìƒì„± (ìˆ˜ì •ëœ train_dataset ì£¼ì…)
# ì—¬ê¸°ì„œ ìƒˆë¡œìš´ train_datasetì´ ë“¤ì–´ê°€ì•¼ ëª¨ë¸ì´ 'ì±…ìƒ' ê°™ì€ ì˜¤ë‹µì„ í•™ìŠµí•©ë‹ˆë‹¤.
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    compute_metrics=compute_metrics,
)

# 4. ì¬í•™ìŠµ ì‹œì‘
print("ğŸš€ Hard Negativeê°€ í¬í•¨ëœ ë°ì´í„°ë¡œ í•™ìŠµì„ ë‹¤ì‹œ ì‹œì‘í•©ë‹ˆë‹¤...")
trainer.train()

# 1. í•™ìŠµ ë°ì´í„° 10%ë§Œ ìƒ˜í”Œë§
small_train_df = train_df.sample(frac=0.1, random_state=SEED)
# 2. ê²€ì¦ ë°ì´í„°ë„ 20% ì •ë„ë§Œ ìƒ˜í”Œë§ (í‰ê°€ ì‹œê°„ì„ ì¤„ì´ê¸° ìœ„í•´)
small_val_df = val_df.sample(frac=0.2, random_state=SEED)

# 3. ë°ì´í„°ì…‹ ë‹¤ì‹œ ìƒì„± (MAX_LENGTHë¥¼ 128ë¡œ ì¤„ì´ë©´ ë” ë¹¨ë¼ì§‘ë‹ˆë‹¤!)
# 'input_with_context' ì»¬ëŸ¼ì„ ì‚¬ìš©í•˜ëŠ”ì§€ ê¼­ í™•ì¸í•˜ì„¸ìš”!
train_dataset = QualityEvalDataset(small_train_df, tokenizer, max_length=330)
val_dataset = QualityEvalDataset(small_val_df, tokenizer, max_length=330)

# 4. Trainer ì¬ì„ ì–¸ (ìƒˆë¡œìš´ ë°ì´í„°ì…‹ì„ ì£¼ì…)
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset, # ì¤„ì–´ë“  ë°ì´í„°ì…‹
    eval_dataset=val_dataset,    # ì¤„ì–´ë“  ë°ì´í„°ì…‹
    compute_metrics=compute_metrics,
)

# 5. í•™ìŠµ ì‹œì‘
print(f"ğŸš€ ìƒ˜í”Œë§ ë°ì´í„°({len(train_dataset)}ê°œ)ë¡œ ì¾Œì† í•™ìŠµ ì‹œì‘...")
trainer.train()
print("âœ… í•™ìŠµ ì™„ë£Œ!")

"""## 10. í‰ê°€"""

# Validation ë°ì´í„°ë¡œ í‰ê°€
eval_results = trainer.evaluate()

print("=" * 50)
print("í‰ê°€ ê²°ê³¼")
print("=" * 50)
for key, value in eval_results.items():
    if 'loss' in key or 'f1' in key or 'match' in key:
        print(f"{key}: {value:.4f}")

# ê¸°ì¤€ë³„ ì •í™•ë„ ì¶œë ¥
print("\n" + "=" * 50)
print("ê¸°ì¤€ë³„ ì •í™•ë„")
print("=" * 50)
for criterion in CRITERIA:
    key = f'eval_{criterion}_acc'
    if key in eval_results:
        print(f"{criterion}: {eval_results[key]:.4f}")

"""## 11. ëª¨ë¸ ì €ì¥"""

# ëª¨ë¸ ì €ì¥
save_path = './outputs/klue-roberta-base-final'
trainer.save_model(save_path)
tokenizer.save_pretrained(save_path)

print(f"ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {save_path}")

"""## 12. ì¶”ë¡  ì˜ˆì‹œ"""

## ì¶”ë¡ ìš© ì…ë ¥ êµ¬ì„± í•¨ìˆ˜

def format_input_with_history(history, current_question, current_response, window_size=2):
    """
    history: [{'q': 'ì§ˆë¬¸1', 'a': 'ë‹µë³€1'}, {'q': 'ì§ˆë¬¸2', 'a': 'ë‹µë³€2'}] í˜•íƒœì˜ ë¦¬ìŠ¤íŠ¸
    """
    # 1. ìµœê·¼ window_sizeë§Œí¼ì˜ ëŒ€í™”ë§Œ ì¶”ì¶œ
    recent_history = history[-window_size:] if history else []

    # 2. [SEP]ë¥¼ ì´ìš©í•´ ì´ì „ ë§¥ë½ ìƒì„±
    history_text = ""
    for h in recent_history:
        history_text += f"{h['q']} [SEP] {h['a']} [SEP] "

    # 3. ìµœì¢… í¬ë§·íŒ…: [ì´ì „ ë§¥ë½] + í˜„ì¬ ì§ˆë¬¸ + [SEP] + í˜„ì¬ ë‹µë³€
    full_input = f"{history_text}{current_question} [SEP] {current_response}"
    return full_input

def predict(text: str, model, tokenizer, device):
    """ë‹¨ì¼ í…ìŠ¤íŠ¸ì— ëŒ€í•œ ì˜ˆì¸¡ ìˆ˜í–‰"""
    model.eval()

    encoding = tokenizer(
        text,
        truncation=True,
        max_length=MAX_LENGTH,
        padding='max_length',
        return_tensors='pt'
    )

    encoding = {k: v.to(device) for k, v in encoding.items()}

    with torch.no_grad():
        outputs = model(**encoding)
        logits = outputs.logits
        probs = torch.sigmoid(logits).cpu().numpy()[0]
        preds = (probs > 0.5).astype(int)

    results = {}
    for i, criterion in enumerate(CRITERIA):
        results[criterion] = {
            'prediction': int(preds[i]),
            'probability': float(probs[i])
        }

    return results

# 1. ì´ì „ ëŒ€í™” ê¸°ë¡ (ì˜ˆì‹œ)
dialogue_history = [
    {"q": "ìš”ì¦˜ ë³¼ë§Œí•œ ì˜í™” ì¶”ì²œí•´ì¤˜.", "a": "ìµœê·¼ ê°œë´‰í•œ 'ì¸ì‚¬ì´ë“œ ì•„ì›ƒ 2'ê°€ ì•„ì£¼ ì¸ê¸°ì˜ˆìš”!"},
    {"q": "ê·¸ê±° ì¥ë¥´ê°€ ë­ì•¼?", "a": "ì• ë‹ˆë©”ì´ì…˜ì´ì íŒíƒ€ì§€ ì˜í™”ì…ë‹ˆë‹¤. ê°ì •ë“¤ì„ ìºë¦­í„°í™”í•´ì„œ ì–´ë¥¸ë“¤ë„ ì¢‹ì•„í•´ìš”."}
]

# 2. í˜„ì¬ í‰ê°€í•˜ê³  ì‹¶ì€ ì§ˆë¬¸ê³¼ ì‘ë‹µ
current_q = "ê·¸ê±° ì£¼ì¸ê³µ ì´ë¦„ì´ ë­ì•¼?"
current_a = "ì£¼ì¸ê³µì˜ ì´ë¦„ì€ 'ë¼ì¼ë¦¬'ì…ë‹ˆë‹¤. ì´ë²ˆ í¸ì—ì„œëŠ” ìƒˆë¡œìš´ ê°ì •ì¸ 'ë¶ˆì•ˆì´'ë„ ë“±ì¥í•´ìš”."

# 3. í•™ìŠµ ë•Œì™€ ë™ì¼í•œ í¬ë§·ìœ¼ë¡œ ë³‘í•© (window_size=2)
formatted_input = format_input_with_history(dialogue_history, current_q, current_a, window_size=2)

print(f"--- ëª¨ë¸ ì…ë ¥ í…ìŠ¤íŠ¸ ---\n{formatted_input}\n")

# 4. ì˜ˆì¸¡ ìˆ˜í–‰
results = predict(formatted_input, model, tokenizer, device)

# ê²°ê³¼ ì¶œë ¥ (ê¸°ì¡´ê³¼ ë™ì¼)
print("=" * 50)
print(f"ğŸ™‹ ì§ˆë¬¸: {current_q}")
print(f"ğŸ¤– ì‘ë‹µ: {current_a}")
print("=" * 50)
for criterion, values in results.items():
    status = "âœ…" if values['prediction'] == 1 else "âŒ"
    print(f"{status} {criterion:25} | {values['probability']:.2%}")

# ì¶”ë¡  í…ŒìŠ¤íŠ¸
sample_question = "í•œêµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì•¼?"
sample_response = "ê°€ë‚˜ë‹¤ë¼ë§ˆë°”ì‚¬"
sample_input = f"{sample_question} [SEP] {sample_response}"

print(f"ì§ˆë¬¸: {sample_question}")
print(f"ì‘ë‹µ: {sample_response}")
print("\n" + "=" * 50)
print("ì˜ˆì¸¡ ê²°ê³¼")
print("=" * 50)

results = predict(sample_input, model, tokenizer, device)
for criterion, values in results.items():
    status = "âœ“" if values['prediction'] == 1 else "âœ—"
    print(f"{status} {criterion}: {values['probability']:.2%}")

