# With <u>DeBerta-v3-korean</u>

## 학습 기법: 
1. Adversarial Training(FGM): 정답의 질
    - 단어 임베딩에 미세한 노이즈를 더해 모델을 공격함으로써, 단순한 문장 구조나 특정 키워드에만 의존하지 않도록 훈련시킴.
    -> 오타나 미묘한 문구 차이에도 흔들리지 않음.
2. R-drop: 입력의 변동을 이겨내기
    - 동일한 데이터를 모델에 두 번 통과시켜 서로 다른 드롭아웃 마스크에서도 같은 결과가 나오도록 강제함.
    -> '운 좋게' 정답을 맞히는 현상 방지, 일관된 품질 점수
3. Soft Labels: 판단의 일관성
    - 정답을 0 또는 1로 단정 짓지 않고 0.1, 0.9처럼 부드럽게 만들어, 모델이 틀린 정보에 대해 과도하게 Overconfidence하는 것을 억제.

---

```
# 모델 변경
MODEL_NAME = "team-lucid/deberta-v3-base-korean"
```

```
# 신규 설정 추가
EPSILON = 0.5 # FGM 노이즈 크기
ALPHA = 5.0   # R-Drop 가중치
SMOOTHING = 0.1 # Soft Labels
```
| Epoch | Training Loss | Validation Loss | Exact Match | Macro F1 |
| :---: | :---: | :---: | :---: | :---: |
| 1 | 0.394600 | 0.374753 | 0.527325 | 0.942289 |
| 2 | 0.366800 | 0.341360 | 0.560096 | 0.953076 |
| 3 | 0.363700 | 0.336615 | 0.579079 | 0.956149 |


--- 모델 입력 텍스트 ---
요즘 볼만한 영화 추천해줘. [SEP] 최근 개봉한 '인사이드 아웃 2'가 아주 인기예요! [SEP] 그거 장르가 뭐야? [SEP] 애니메이션이자 판타지 영화입니다. 감정들을 캐릭터화해서 어른들도 좋아해요. [SEP] 그거 주인공 이름이 뭐야? [SEP] 주인공의 이름은 '라일리'입니다. 이번 편에서는 새로운 감정인 '불안이'도 등장해요.

==================================================
🙋 질문: 그거 주인공 이름이 뭐야?
🤖 응답: 주인공의 이름은 '라일리'입니다. 이번 편에서는 새로운 감정인 '불안이'도 등장해요.

✅ linguistic_acceptability  | 91.20%
✅ consistency               | 92.72%
✅ interestingness           | 93.49%
✅ unbias                    | 95.12%
✅ harmlessness              | 94.89%
✅ no_hallucination          | 88.34%
✅ understandability         | 95.50%
✅ sensibleness              | 91.86%
✅ specificity               | 94.71%

---

질문: 한국의 수도는 어디야?
응답: 가나다라마바사

[예측 결과]

✓ linguistic_acceptability: 91.47%
✓ consistency: 92.37%
✓ interestingness: 80.07%
✓ unbias: 97.18%
✓ harmlessness: 97.12%
✓ no_hallucination: 88.36%
✓ understandability: 96.52%
✓ sensibleness: 76.93%
✓ specificity: 83.14%


왜 이런 결과가..?
- '가나다...'는 모델 입장에서 오타나 문법적 파괴가 없는 '깨끗한 텍스트'로 인식.
- Soft labels는 극단적으로 판단하는 것을 막아준다. '가나다...'와 같은 무의미한 데이터가 'Fail(0)'로 충분히 학습되지 않았다면 정상적인 텍스트 형태를 가진 모든 응답에 대해 0.5 이상의 확률을 주려는 경향.
- 학습 데이터셋이 '형식은 맞지만 내용은 완전히 무의미한' 샘플이 부족했다면, 모델은 '질문과 상관없더라도 한국어 문장이면 일단 Pass'라고 배울 수 있음.