# -*- coding: utf-8 -*-
"""Test_new2.ipynbì˜ ì‚¬ë³¸

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uAQBhJcYvh91cqbUO04Hkoy5rKHrSvnW

# AI í’ˆì§ˆ í‰ê°€ ëª¨ë¸ í•™ìŠµ - klue/roberta-base

ì´ ë…¸íŠ¸ë¶ì€ AI ì‘ë‹µ í’ˆì§ˆ í‰ê°€ë¥¼ ìœ„í•œ Multi-label Classification ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤.

**í‰ê°€ ê¸°ì¤€ (9ê°œ)**:

- linguistic_acceptability (ì–¸ì–´ì  ìˆ˜ìš©ì„±)
- consistency (ì¼ê´€ì„±)
- interestingness (í¥ë¯¸ë¡œì›€)
- unbias (í¸í–¥ ì—†ìŒ)
- harmlessness (ë¬´í•´ì„±)
- no_hallucination (í™˜ê° ì—†ìŒ)
- understandability (ì´í•´ ê°€ëŠ¥ì„±)
- sensibleness (í•©ë¦¬ì„±)
- specificity (êµ¬ì²´ì„±)

## 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° ì„í¬íŠ¸
"""

# !pip install torch transformers datasets pandas scikit-learn tqdm -q

from google.colab import drive
drive.mount('/content/drive/')

import pandas as pd
import numpy as np
import torch
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    TrainingArguments,
    Trainer,
)
from sklearn.metrics import f1_score, accuracy_score
from tqdm.auto import tqdm
import warnings

warnings.filterwarnings('ignore')

# GPU í™•ì¸
device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu')
print(f"Using device: {device}")

"""## 2. ì„¤ì •"""

MODEL_NAME = "team-lucid/deberta-v3-base-korean" # ëª¨ë¸ ë³€ê²½
MAX_LENGTH = 330
BATCH_SIZE = 32 # DeBERTaëŠ” ë©”ëª¨ë¦¬ ì ìœ ìœ¨ì´ ë†’ì•„ ë°°ì¹˜ ì‚¬ì´ì¦ˆë¥¼ ë‚®ì¶”ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.
LEARNING_RATE = 1e-5 # DeBERTaëŠ” ë‚®ì€ LRì—ì„œ ì•ˆì •ì ì…ë‹ˆë‹¤.
NUM_EPOCHS = 3
SEED = 42

# ì‹ ê·œ ì„¤ì • ì¶”ê°€
EPSILON = 0.5 # FGM ë…¸ì´ì¦ˆ í¬ê¸°
ALPHA = 5.0   # R-Drop ê°€ì¤‘ì¹˜
SMOOTHING = 0.1 # Soft Labels

CRITERIA = [
    'linguistic_acceptability', 'consistency', 'interestingness',
    'unbias', 'harmlessness', 'no_hallucination',
    'understandability', 'sensibleness', 'specificity'
]
NUM_LABELS = len(CRITERIA)
torch.manual_seed(SEED)

"""## 3. ë°ì´í„° ë¡œë“œ"""

# # unzip
# unzip_path = '/content/drive/MyDrive/AI_data/data.zip'
# !unzip -qq {unzip_path} -d /content/drive/MyDrive/AI_data/

# Training ë° Validation ë°ì´í„° ë¡œë“œ (aggregated ë²„ì „ ì‚¬ìš© - majority voting ê²°ê³¼)
train_df = pd.read_csv('/content/drive/MyDrive/AI_data/data/train/training_all_aggregated.csv', encoding='utf-8-sig')
val_df = pd.read_csv('/content/drive/MyDrive/AI_data/data/val/validation_all_aggregated.csv', encoding='utf-8-sig')

print(f"Training ë°ì´í„°: {len(train_df):,}ê°œ")
print(f"Validation ë°ì´í„°: {len(val_df):,}ê°œ")

train_df['topic'].value_counts()

# ë°ì´í„° í™•ì¸
train_df[train_df['topic']=='ì—”í„°í…Œì¸ë¨¼íŠ¸, ì˜¤ë½, ì˜ˆìˆ '].head(10)

# 1. ì§€í‘œ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ ìƒì„± (ì»¬ëŸ¼ëª…: í•œê¸€ ì„¤ëª…)
quality_metrics = {
    "linguistic_acceptability_majority": "ì–¸ì–´í•™ì  ìˆ˜ìš©ì„±",
    "consistency_majority": "ì¼ê´€ì„±",
    "interestingness_majority": "í¥ë¯¸ì„±",
    "unbias_majority": "ë¹„í¸í–¥ì„±",
    "harmlessness_majority": "ë¬´í•´ì„±",
    "no_hallucination_majority": "ì •ë³´ ê·¼ê±°ì„±",
    "understandability_majority": "ì´í•´ ê°€ëŠ¥ì„±",
    "sensibleness_majority": "ë‹µë³€ì˜ ì ì ˆì„±",
    "specificity_majority": "ë‹µë³€ì˜ êµ¬ì²´ì„±"
}

target_topic = 'ì—”í„°í…Œì¸ë¨¼íŠ¸, ì˜¤ë½, ì˜ˆìˆ '
entertainment_df = train_df[train_df['topic'] == target_topic]

for i, row in entertainment_df.tail(5).iterrows():
    print(f"[{i+1}ë²ˆ ë°ì´í„°]")
    print(f"ğŸ™‹ ì§ˆë¬¸: {row['human_question']}")
    print(f"ğŸ¤– ì‘ë‹µ: {row['bot_response']}")
    print("\n[ğŸ“Š í’ˆì§ˆ í‰ê°€ ìƒì„¸]")

    # 9ê°€ì§€ ì§€í‘œë¥¼ ìˆœíšŒí•˜ë©° ì¶œë ¥
    for col, name in quality_metrics.items():
        status = "âœ… Pass" if row[col] == 1 else "âŒ Fail"
        print(f" - {name}: {status}")

    print("-" * 50)

# ì»¬ëŸ¼ í™•ì¸
print("ì»¬ëŸ¼ ëª©ë¡:")
print(train_df.columns.tolist())

def create_hard_negatives(df, negative_ratio=0.2, seed=42):
    """ê¸°ì¡´ ë°ì´í„°ì˜ ë‹µë³€ì„ ì„ì–´ 'ë‚´ìš©ì´ í‹€ë¦°' ë¶€ì • ìƒ˜í”Œì„ ìƒì„±í•©ë‹ˆë‹¤."""
    n_samples = int(len(df) * negative_ratio)
    neg_df = df.sample(n=n_samples, random_state=seed).copy()

    # ë‹¤ë¥¸ í–‰ì˜ ë‹µë³€ì„ ë¬´ì‘ìœ„ë¡œ ê°€ì ¸ì™€ ë§¤ì¹­ (ë‚´ìš© ë¶ˆì¼ì¹˜ ìœ ë„)
    shuffled_responses = df.sample(n=n_samples, random_state=seed+1)['bot_response'].values
    neg_df['bot_response'] = shuffled_responses

    # ëª¨ë“  í’ˆì§ˆ ì§€í‘œ ë¼ë²¨ì„ 0(Fail)ìœ¼ë¡œ ì„¤ì •
    for criterion in CRITERIA:
        neg_df[f"{criterion}_majority"] = 0

    print(f"âœ… {n_samples}ê°œì˜ Hard Negative ë°ì´í„° ìƒì„± ì™„ë£Œ!")
    return neg_df

import pandas as pd
from tqdm import tqdm
import numpy as np # ğŸ†• ì¶”ê°€ (ëœë¤ ì‹œë“œ ë“±ì„ ìœ„í•´ í•„ìš”)

# 1. ê¸°ì¡´ í•¨ìˆ˜ ìœ ì§€
def merge_dialogue_context(df, window_size=2):

    df = df.sort_values(['conversation_id', 'utterance_index']).reset_index(drop=True)
    contexts = []
    for i in tqdm(range(len(df)), desc="Merging Contexts"):
        current_row = df.iloc[i]
        c_id = current_row['conversation_id']
        history = df[(df['conversation_id'] == c_id) & (df.index < i)].tail(window_size)
        history_text = ""
        for _, h_row in history.iterrows():
            history_text += f"{h_row['human_question']} [SEP] {h_row['bot_response']} [SEP] "
        full_input = f"{history_text}{current_row['human_question']} [SEP] {current_row['bot_response']}"
        contexts.append(full_input)
    df['input_with_context'] = contexts
    return df

# 2. ğŸ†• [í•¨ìˆ˜ ì¶”ê°€] Hard Negative ìƒì„± í•¨ìˆ˜
def create_hard_negatives(df, negative_ratio=0.2, seed=42):
    """ê¸°ì¡´ ë°ì´í„°ì˜ ë‹µë³€ì„ ì„ì–´ 'ë‚´ìš©ì´ í‹€ë¦°' ë¶€ì • ìƒ˜í”Œì„ ìƒì„±í•©ë‹ˆë‹¤."""
    n_samples = int(len(df) * negative_ratio)
    neg_df = df.sample(n=n_samples, random_state=seed).copy()

    # ë‹¤ë¥¸ í–‰ì˜ ë‹µë³€ì„ ë¬´ì‘ìœ„ë¡œ ê°€ì ¸ì™€ ë§¤ì¹­ (ë‚´ìš© ë¶ˆì¼ì¹˜ ìœ ë„)
    shuffled_responses = df.sample(n=n_samples, random_state=seed+1)['bot_response'].values
    neg_df['bot_response'] = shuffled_responses

    # ëª¨ë“  í’ˆì§ˆ ì§€í‘œ ë¼ë²¨ì„ 0(Fail)ìœ¼ë¡œ ì„¤ì •
    for criterion in CRITERIA:
        neg_df[criterion] = 0
    return neg_df

# --- ì ìš©í•˜ê¸° ---

# [ë³€ê²½ í¬ì¸íŠ¸ 1] í•™ìŠµ ë°ì´í„° í™•ì¥
print("ğŸ› ï¸ Hard Negative ë°ì´í„° ìƒì„± ë° í•™ìŠµ ë°ì´í„° í™•ì¥ ì¤‘...")
hard_neg_df = create_hard_negatives(train_df, negative_ratio=0.2)
# ê¸°ì¡´ train_dfì™€ ìƒì„±ëœ ë¶€ì • ë°ì´í„°ë¥¼ í•©ì¹©ë‹ˆë‹¤.
extended_train_df = pd.concat([train_df, hard_neg_df], axis=0, ignore_index=True)

# [ë³€ê²½ í¬ì¸íŠ¸ 2] í™•ì¥ëœ ë°ì´í„°ì…‹(extended_train_df)ìœ¼ë¡œ ë§¥ë½ ë³‘í•© ì‹¤í–‰
print("í•™ìŠµ ë°ì´í„° ë§¥ë½ ë³‘í•© ì¤‘ (ë¶€ì • ìƒ˜í”Œ í¬í•¨)...")
train_df = merge_dialogue_context(extended_train_df, window_size=2)

# ê²€ì¦ ë°ì´í„°ëŠ” ì›ë³¸ ê·¸ëŒ€ë¡œ ìœ ì§€ (í‰ê°€ì˜ ê°ê´€ì„±ì„ ìœ„í•´)
print("ê²€ì¦ ë°ì´í„° ë§¥ë½ ë³‘í•© ì¤‘...")
val_df = merge_dialogue_context(val_df, window_size=2)

"""## 4. ë°ì´í„° ì „ì²˜ë¦¬"""

def preprocess_data(df):
    df = df.copy()
    df['human_question'] = df['human_question'].fillna('')
    df['bot_response'] = df['bot_response'].fillna('')
    # Cross-Encoder í˜•ì‹ êµ¬ì„±
    df['input_text'] = df['human_question'] + ' [SEP] ' + df['bot_response']
    return df

train_df = preprocess_data(train_df)
val_df = preprocess_data(val_df)

print(f"ì „ì²˜ë¦¬ í›„ Training ë°ì´í„°: {len(train_df):,}ê°œ")
print(f"ì „ì²˜ë¦¬ í›„ Validation ë°ì´í„°: {len(val_df):,}ê°œ")

# ë ˆì´ë¸” ë¶„í¬ í™•ì¸
target_cols = [f'{c}_majority' for c in CRITERIA]

print("=" * 50)
print("ë ˆì´ë¸” ë¶„í¬ (Training)")
print("=" * 50)
for col in target_cols:
    pos_ratio = train_df[col].mean()
    print(f"{col}: {pos_ratio:.2%} positive")

"""## 5. Tokenizer ë¡œë“œ"""

!pip install huggingface_hub -q

from huggingface_hub import notebook_login
notebook_login() # ì—¬ê¸°ì— ë³¸ì¸ì˜ Hugging Face Access Tokenì„ ì…ë ¥í•©ë‹ˆë‹¤.

tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_auth_token=True)
# DeBERTa-v3ëŠ” ë‚´ë¶€ì ìœ¼ë¡œ íŠ¹ì • í† í° ì²˜ë¦¬ê°€ ë‹¤ë¥´ë¯€ë¡œ ë°˜ë“œì‹œ í•´ë‹¹ ëª¨ë¸ì˜ í† í¬ë‚˜ì´ì €ë¥¼ ì¨ì•¼ í•©ë‹ˆë‹¤.

print(f"Tokenizer ë¡œë“œ ì™„ë£Œ: {MODEL_NAME}")
print(f"Vocab size: {tokenizer.vocab_size:,}")

# í† í¬ë‚˜ì´ì € í…ŒìŠ¤íŠ¸
sample_text = train_df['input_with_context'].iloc[0]
print(f"ìƒ˜í”Œ í…ìŠ¤íŠ¸:\n{sample_text}\n")

tokens = tokenizer(sample_text, truncation=True, max_length=MAX_LENGTH)
print(f"í† í° ìˆ˜: {len(tokens['input_ids'])}")

# 1. ìƒˆë¡œìš´ 'input_with_context' ê¸°ì¤€ í† í° ê¸¸ì´ ê³„ì‚°
token_lengths = [len(tokenizer.encode(text, add_special_tokens=True)) for text in tqdm(train_df['input_with_context'], desc="Checking New Lengths")]

# 2. í†µê³„ì¹˜ í™•ì¸
print(f"\n[ğŸ“Š ë§¥ë½ í¬í•¨ í† í° í†µê³„]")
print(f" - 95th percentile: {np.percentile(token_lengths, 95)}")
print(f" - 99th percentile: {np.percentile(token_lengths, 99)}")
print(f" - ìµœëŒ€ ê¸¸ì´: {np.max(token_lengths)}")

# 3. ë°ì´í„° ì €ì¥ (ë‚´ì¼ ë°”ë¡œ ë¶ˆëŸ¬ì™€ì„œ ì“¸ ìˆ˜ ìˆê²Œ)
# êµ¬ê¸€ ë“œë¼ì´ë¸Œ ê²½ë¡œë¡œ ì„¤ì •í•˜ì„¸ìš”.
train_df.to_csv('/content/drive/MyDrive/final_train_context.csv', index=False)
val_df.to_csv('/content/drive/MyDrive/final_val_context.csv', index=False)
print("\nâœ… ìµœì¢… ë°ì´í„°ì…‹ ì €ì¥ ì™„ë£Œ!")

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm

# 1. ëª¨ë“  input_textì˜ í† í° ê¸¸ì´ ê³„ì‚° (ì‹œê°„ì´ ì¡°ê¸ˆ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)
token_lengths = [len(tokenizer.encode(text, add_special_tokens=True)) for text in tqdm(train_df['input_with_context'], desc="Calculating lengths")]

# 2. í†µê³„ì¹˜ ê³„ì‚°
max_len = np.max(token_lengths)
mean_len = np.mean(token_lengths)
p95 = np.percentile(token_lengths, 95)
p99 = np.percentile(token_lengths, 99)

print(f"\n[ğŸ“Š Token Length Statistics]")
print(f" - ì „ì²´ ë°ì´í„° ìˆ˜: {len(token_lengths)}ê°œ")
print(f" - ìµœëŒ€ í† í° ê¸¸ì´: {max_len}")
print(f" - í‰ê·  í† í° ê¸¸ì´: {mean_len:.2f}")
print(f" - 95% ë°ì´í„°ê°€ í¬í•¨ë˜ëŠ” ê¸¸ì´: {p95}")
print(f" - 99% ë°ì´í„°ê°€ í¬í•¨ë˜ëŠ” ê¸¸ì´: {p99}")

# 3. ë¶„í¬ ì‹œê°í™”
plt.figure(figsize=(12, 6))
sns.histplot(token_lengths, bins=50, color='teal', kde=True)
plt.axvline(p95, color='orange', linestyle='--', label=f'95th Percentile ({p95:.0f})')
plt.axvline(p99, color='red', linestyle='--', label=f'99th Percentile ({p99:.0f})')
plt.title('Token Length Distribution (Question + Answer)')
plt.xlabel('Number of Tokens')
plt.ylabel('Count')
plt.legend()
plt.show()

"""## 6. Dataset í´ë˜ìŠ¤ ì •ì˜"""

class QualityEvalDataset(Dataset):
    def __init__(self, df, tokenizer, max_length=330, smoothing=0.1):
        self.df = df.reset_index(drop=True)
        self.tokenizer = tokenizer
        self.max_length = max_length
        self.target_cols = [f'{c}_majority' for c in CRITERIA]
        self.smoothing = smoothing

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        # ìˆ˜ì •: 'input_text' ëŒ€ì‹  ë§¥ë½ì´ í¬í•¨ëœ 'input_with_context' ì‚¬ìš©
        text = row['input_with_context'] if 'input_with_context' in row else row['input_text']

        labels = row[self.target_cols].values.astype(np.float32)
        soft_labels = labels * (1.0 - self.smoothing) + (0.5 * self.smoothing)

        encoding = self.tokenizer(
            text, truncation=True, max_length=self.max_length,
            padding='max_length', return_tensors='pt'
        )
        return {
            'input_ids': encoding['input_ids'].squeeze(0),
            'attention_mask': encoding['attention_mask'].squeeze(0),
            'labels': torch.tensor(soft_labels, dtype=torch.float)
        }

# Dataset ìƒì„±
train_dataset = QualityEvalDataset(train_df, tokenizer, MAX_LENGTH)
val_dataset = QualityEvalDataset(val_df, tokenizer, MAX_LENGTH)

print(f"Train dataset size: {len(train_dataset):,}")
print(f"Val dataset size: {len(val_dataset):,}")

# Dataset í™•ì¸
sample = train_dataset[0]
print(f"input_ids shape: {sample['input_ids'].shape}")
print(f"attention_mask shape: {sample['attention_mask'].shape}")
print(f"labels shape: {sample['labels'].shape}")
print(f"labels: {sample['labels']}")

"""## 7. ëª¨ë¸ ë¡œë“œ"""

# Multi-label Classificationì„ ìœ„í•œ ëª¨ë¸ ë¡œë“œ
model = AutoModelForSequenceClassification.from_pretrained(
    MODEL_NAME, num_labels=NUM_LABELS, problem_type="multi_label_classification"
)
model.to(device)
print(f"ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {MODEL_NAME}")
print(f"íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in model.parameters()):,}")

"""## 8. í‰ê°€ ì§€í‘œ í•¨ìˆ˜"""

def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    probs = torch.sigmoid(torch.tensor(predictions)).numpy()
    preds = (probs > 0.5).astype(int)
    binary_labels = (labels > 0.5).astype(int)

    return {
        'exact_match': np.all(preds == binary_labels, axis=1).mean(),
        'macro_f1': f1_score(binary_labels, preds, average='macro', zero_division=0)
    }

"""## 9. Trainer ì„¤ì • ë° í•™ìŠµ"""

class FGM:
    def __init__(self, model):
        self.model = model
        self.backup = {}
    def attack(self, epsilon=0.5, emb_name='word_embeddings'):
        for name, param in self.model.named_parameters():
            if param.requires_grad and emb_name in name:
                self.backup[name] = param.data.clone()
                norm = torch.norm(param.grad)
                if norm != 0:
                    r_at = epsilon * param.grad / norm
                    param.data.add_(r_at)
    def restore(self, emb_name='word_embeddings'):
        for name, param in self.model.named_parameters():
            if param.requires_grad and emb_name in name:
                param.data = self.backup[name]
        self.backup = {}

# 1. CustomTrainer ì™„ë²½ êµ¬í˜„ (R-Drop í¬í•¨)
class CustomTrainer(Trainer):
    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):
        labels = inputs.get("labels")

        # R-Dropì„ ìœ„í•´ ëª¨ë¸ì„ ë‘ ë²ˆ í†µê³¼ (ì„œë¡œ ë‹¤ë¥¸ ë“œë¡­ì•„ì›ƒ ë§ˆìŠ¤í¬ ì ìš©)
        outputs1 = model(**inputs)
        outputs2 = model(**inputs)

        logits1 = outputs1.get("logits")
        logits2 = outputs2.get("logits")

        # ê¸°ë³¸ ì†ì‹¤ (BCE)
        loss_fct = torch.nn.BCEWithLogitsLoss()
        loss1 = loss_fct(logits1, labels)
        loss2 = loss_fct(logits2, labels)
        base_loss = 0.5 * (loss1 + loss2)

        # R-Drop ì†ì‹¤ (KL-Divergence) ê³„ì‚°
        p1 = torch.sigmoid(logits1)
        p2 = torch.sigmoid(logits2)

        # ì–‘ë°©í–¥ KL-Divergence
        kl_loss = F.kl_div(p1.log(), p2, reduction='batchmean') + \
                  F.kl_div(p2.log(), p1, reduction='batchmean')

        # ìµœì¢… ì†ì‹¤ = BCE + alpha * KL
        total_loss = base_loss + ALPHA * (kl_loss / 4)

        return (total_loss, outputs1) if return_outputs else total_loss

def training_step(self, model, inputs, num_items_in_batch=None):
        model.train()
        inputs = self._prepare_inputs(inputs)

        # 1. ê¸°ë³¸ ì†ì‹¤ ë° ì—­ì „íŒŒ
        loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
        # ìˆ˜ì • í¬ì¸íŠ¸: FP16(Mixed Precision) í˜¸í™˜ì„ ìœ„í•´ accelerator ì‚¬ìš©
        self.accelerator.backward(loss)

        # 2. FGM ê³µê²© (Adversarial Training)
        fgm = FGM(model)
        fgm.attack(epsilon=EPSILON)

        # 3. ì ëŒ€ì  ì†ì‹¤ ë° ì—­ì „íŒŒ
        loss_adv = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
        # ìˆ˜ì • í¬ì¸íŠ¸: FP16 í˜¸í™˜ì„ ìœ„í•´ accelerator ì‚¬ìš©
        self.accelerator.backward(loss_adv)

        fgm.restore()

        return loss.detach()

# 2. TrainingArguments ë° Trainer ì„¤ì •
training_args = TrainingArguments(
    output_dir='./outputs/deberta-v3-quality',
    num_train_epochs=NUM_EPOCHS,
    per_device_train_batch_size=32,
    gradient_accumulation_steps=2,       # 2ë‹¨ê³„ ëˆ„ì í•˜ì—¬ ì‹¤ì§ˆì  ë°°ì¹˜ëŠ” 64 íš¨ê³¼
    eval_strategy='epoch',
    save_strategy='epoch',
    load_best_model_at_end=True,
    metric_for_best_model='macro_f1',
    learning_rate=LEARNING_RATE,
    fp16=True,                          # ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ í•„ìˆ˜
    logging_steps=50,
    seed=SEED
    )

# 3. ìƒ˜í”Œë§ ë°ì´í„°ë¡œ ë°ì´í„°ì…‹ ì¤€ë¹„
small_train_df = train_df.sample(frac=0.1, random_state=SEED)
small_val_df = val_df.sample(frac=0.2, random_state=SEED)

train_dataset = QualityEvalDataset(small_train_df, tokenizer, max_length=MAX_LENGTH)
val_dataset = QualityEvalDataset(small_val_df, tokenizer, max_length=MAX_LENGTH)

# 4. ë°˜ë“œì‹œ CustomTrainerë¡œ ì„ ì–¸!
trainer = CustomTrainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    compute_metrics=compute_metrics,
)

print(f"ğŸš€ DeBERTa-v3 + FGM + R-Drop í•™ìŠµ ì‹œì‘...")
trainer.train()

# 1. í•™ìŠµ ë°ì´í„° 10%ë§Œ ìƒ˜í”Œë§
small_train_df = train_df.sample(frac=0.1, random_state=SEED)
# 2. ê²€ì¦ ë°ì´í„°ë„ 20% ì •ë„ë§Œ ìƒ˜í”Œë§ (í‰ê°€ ì‹œê°„ì„ ì¤„ì´ê¸° ìœ„í•´)
small_val_df = val_df.sample(frac=0.2, random_state=SEED)

# 3. ë°ì´í„°ì…‹ ë‹¤ì‹œ ìƒì„± (MAX_LENGTHë¥¼ 128ë¡œ ì¤„ì´ë©´ ë” ë¹¨ë¼ì§‘ë‹ˆë‹¤!)
# 'input_with_context' ì»¬ëŸ¼ì„ ì‚¬ìš©í•˜ëŠ”ì§€ ê¼­ í™•ì¸í•˜ì„¸ìš”!
train_dataset = QualityEvalDataset(small_train_df, tokenizer, max_length=330)
val_dataset = QualityEvalDataset(small_val_df, tokenizer, max_length=330)

# 4. Trainer ì¬ì„ ì–¸ (ìƒˆë¡œìš´ ë°ì´í„°ì…‹ì„ ì£¼ì…)
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset, # ì¤„ì–´ë“  ë°ì´í„°ì…‹
    eval_dataset=val_dataset,    # ì¤„ì–´ë“  ë°ì´í„°ì…‹
    compute_metrics=compute_metrics,
)

# 5. í•™ìŠµ ì‹œì‘
print(f"ğŸš€ ìƒ˜í”Œë§ ë°ì´í„°({len(train_dataset)}ê°œ)ë¡œ ì¾Œì† í•™ìŠµ ì‹œì‘...")
trainer.train()
print("âœ… í•™ìŠµ ì™„ë£Œ!")

"""## 10. í‰ê°€"""

# Validation ë°ì´í„°ë¡œ í‰ê°€
eval_results = trainer.evaluate()

print("=" * 50)
print("í‰ê°€ ê²°ê³¼")
print("=" * 50)
for key, value in eval_results.items():
    if 'loss' in key or 'f1' in key or 'match' in key:
        print(f"{key}: {value:.4f}")

# ê¸°ì¤€ë³„ ì •í™•ë„ ì¶œë ¥
print("\n" + "=" * 50)
print("ê¸°ì¤€ë³„ ì •í™•ë„")
print("=" * 50)
for criterion in CRITERIA:
    key = f'eval_{criterion}_acc'
    if key in eval_results:
        print(f"{criterion}: {eval_results[key]:.4f}")

"""## 11. ëª¨ë¸ ì €ì¥"""

# ëª¨ë¸ ì €ì¥
save_path = './outputs/klue-roberta-base-final'
trainer.save_model(save_path)
tokenizer.save_pretrained(save_path)

print(f"ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {save_path}")

"""## 12. ì¶”ë¡  ì˜ˆì‹œ"""

## ì¶”ë¡ ìš© ì…ë ¥ êµ¬ì„± í•¨ìˆ˜

def format_input_with_history(history, current_question, current_response, window_size=2):
    """
    history: [{'q': 'ì§ˆë¬¸1', 'a': 'ë‹µë³€1'}, {'q': 'ì§ˆë¬¸2', 'a': 'ë‹µë³€2'}] í˜•íƒœì˜ ë¦¬ìŠ¤íŠ¸
    """
    # 1. ìµœê·¼ window_sizeë§Œí¼ì˜ ëŒ€í™”ë§Œ ì¶”ì¶œ
    recent_history = history[-window_size:] if history else []

    # 2. [SEP]ë¥¼ ì´ìš©í•´ ì´ì „ ë§¥ë½ ìƒì„±
    history_text = ""
    for h in recent_history:
        history_text += f"{h['q']} [SEP] {h['a']} [SEP] "

    # 3. ìµœì¢… í¬ë§·íŒ…: [ì´ì „ ë§¥ë½] + í˜„ì¬ ì§ˆë¬¸ + [SEP] + í˜„ì¬ ë‹µë³€
    full_input = f"{history_text}{current_question} [SEP] {current_response}"
    return full_input

def predict(text: str, model, tokenizer, device):
    """ë‹¨ì¼ í…ìŠ¤íŠ¸ì— ëŒ€í•œ ì˜ˆì¸¡ ìˆ˜í–‰"""
    model.eval()

    encoding = tokenizer(
        text,
        truncation=True,
        max_length=MAX_LENGTH,
        padding='max_length',
        return_tensors='pt'
    )

    encoding = {k: v.to(device) for k, v in encoding.items()}

    with torch.no_grad():
        outputs = model(**encoding)
        logits = outputs.logits
        probs = torch.sigmoid(logits).cpu().numpy()[0]
        preds = (probs > 0.5).astype(int)

    results = {}
    for i, criterion in enumerate(CRITERIA):
        results[criterion] = {
            'prediction': int(preds[i]),
            'probability': float(probs[i])
        }

    return results

# 1. ì´ì „ ëŒ€í™” ê¸°ë¡ (ì˜ˆì‹œ)
dialogue_history = [
    {"q": "ìš”ì¦˜ ë³¼ë§Œí•œ ì˜í™” ì¶”ì²œí•´ì¤˜.", "a": "ìµœê·¼ ê°œë´‰í•œ 'ì¸ì‚¬ì´ë“œ ì•„ì›ƒ 2'ê°€ ì•„ì£¼ ì¸ê¸°ì˜ˆìš”!"},
    {"q": "ê·¸ê±° ì¥ë¥´ê°€ ë­ì•¼?", "a": "ì• ë‹ˆë©”ì´ì…˜ì´ì íŒíƒ€ì§€ ì˜í™”ì…ë‹ˆë‹¤. ê°ì •ë“¤ì„ ìºë¦­í„°í™”í•´ì„œ ì–´ë¥¸ë“¤ë„ ì¢‹ì•„í•´ìš”."}
]

# 2. í˜„ì¬ í‰ê°€í•˜ê³  ì‹¶ì€ ì§ˆë¬¸ê³¼ ì‘ë‹µ
current_q = "ê·¸ê±° ì£¼ì¸ê³µ ì´ë¦„ì´ ë­ì•¼?"
current_a = "ì£¼ì¸ê³µì˜ ì´ë¦„ì€ 'ë¼ì¼ë¦¬'ì…ë‹ˆë‹¤. ì´ë²ˆ í¸ì—ì„œëŠ” ìƒˆë¡œìš´ ê°ì •ì¸ 'ë¶ˆì•ˆì´'ë„ ë“±ì¥í•´ìš”."

# 3. í•™ìŠµ ë•Œì™€ ë™ì¼í•œ í¬ë§·ìœ¼ë¡œ ë³‘í•© (window_size=2)
formatted_input = format_input_with_history(dialogue_history, current_q, current_a, window_size=2)

print(f"--- ëª¨ë¸ ì…ë ¥ í…ìŠ¤íŠ¸ ---\n{formatted_input}\n")

# 4. ì˜ˆì¸¡ ìˆ˜í–‰
results = predict(formatted_input, model, tokenizer, device)

# ê²°ê³¼ ì¶œë ¥ (ê¸°ì¡´ê³¼ ë™ì¼)
print("=" * 50)
print(f"ğŸ™‹ ì§ˆë¬¸: {current_q}")
print(f"ğŸ¤– ì‘ë‹µ: {current_a}")
print("=" * 50)
for criterion, values in results.items():
    status = "âœ…" if values['prediction'] == 1 else "âŒ"
    print(f"{status} {criterion:25} | {values['probability']:.2%}")

# ì¶”ë¡  í…ŒìŠ¤íŠ¸
sample_question = "í•œêµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì•¼?"
sample_response = "ê°€ë‚˜ë‹¤ë¼ë§ˆë°”ì‚¬"
sample_input = f"{sample_question} [SEP] {sample_response}"

print(f"ì§ˆë¬¸: {sample_question}")
print(f"ì‘ë‹µ: {sample_response}")
print("\n" + "=" * 50)
print("ì˜ˆì¸¡ ê²°ê³¼")
print("=" * 50)

results = predict(sample_input, model, tokenizer, device)
for criterion, values in results.items():
    status = "âœ“" if values['prediction'] == 1 else "âœ—"
    print(f"{status} {criterion}: {values['probability']:.2%}")

## ë----