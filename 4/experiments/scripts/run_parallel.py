#!/usr/bin/env python
"""
2-GPU ë³‘ë ¬ ì‹¤í—˜ ì‹¤í–‰ê¸°
- GPU 0: noctx ì‹¤í—˜ / Loss ì‹¤í—˜ (ì§ìˆ˜)
- GPU 1: ctx ì‹¤í—˜ / Loss ì‹¤í—˜ (í™€ìˆ˜)
- Phase ê°„ ìë™ ì˜ì¡´ì„±: Phase 1 ì™„ë£Œ í›„ Best Model ìë™ ì„ ì •
"""

import os
import sys
import subprocess
import json
import time
from pathlib import Path
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì„¤ì •
ROOT = Path(__file__).parent.parent
os.chdir(ROOT)

# ìƒ‰ìƒ ì½”ë“œ
GREEN = '\033[0;32m'
BLUE = '\033[0;34m'
CYAN = '\033[0;36m'
RED = '\033[0;31m'
NC = '\033[0m'

# ì„¤ì •
PROGRESS_FILE = ROOT / "outputs" / ".progress"
RESULTS_DIR = ROOT / "outputs" / "results"
LOGS_DIR = ROOT / "logs"

def log_info(msg):
    print(f"{BLUE}[{datetime.now().strftime('%H:%M:%S')}]{NC} {msg}")

def log_ok(msg):
    print(f"{GREEN}[{datetime.now().strftime('%H:%M:%S')}] âœ“{NC} {msg}")

def log_error(msg):
    print(f"{RED}[{datetime.now().strftime('%H:%M:%S')}] âœ—{NC} {msg}")

def log_phase(msg):
    print(f"\n{CYAN}{'â•' * 15} {msg} {'â•' * 15}{NC}\n")

def is_done(name):
    """ì‹¤í—˜ì´ ì´ë¯¸ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸"""
    if not PROGRESS_FILE.exists():
        return False
    with open(PROGRESS_FILE) as f:
        return any(line.startswith(f"{name}:done") for line in f)

def mark_done(name):
    """ì‹¤í—˜ ì™„ë£Œ ê¸°ë¡"""
    PROGRESS_FILE.parent.mkdir(parents=True, exist_ok=True)
    with open(PROGRESS_FILE, 'a') as f:
        f.write(f"{name}:done:{datetime.now()}\n")
    log_ok(f"{name} ì™„ë£Œ")

def run_on_gpu(gpu_id, script, args, name):
    """íŠ¹ì • GPUì—ì„œ ì‹¤í—˜ ì‹¤í–‰ (subprocess)"""
    if is_done(name):
        log_info(f"{name} ì´ë¯¸ ì™„ë£Œ, ìŠ¤í‚µ")
        return None
    
    log_info(f"{name} ì‹œì‘ (GPU {gpu_id})...")
    
    env = os.environ.copy()
    env['CUDA_VISIBLE_DEVICES'] = str(gpu_id)
    
    log_file = LOGS_DIR / f"{name}.log"
    LOGS_DIR.mkdir(parents=True, exist_ok=True)
    
    cmd = ['python', script] + args + ['--run_name', name]
    
    with open(log_file, 'w') as f:
        process = subprocess.Popen(
            cmd,
            env=env,
            stdout=f,
            stderr=subprocess.STDOUT,
            cwd=str(ROOT)
        )
    
    return process

def wait_and_mark(process, name):
    """í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ ëŒ€ê¸° ë° ê¸°ë¡"""
    if process is None:
        return True
    
    returncode = process.wait()
    if returncode == 0:
        mark_done(name)
        return True
    else:
        log_error(f"{name} ì‹¤íŒ¨ (exit code: {returncode})")
        return False

def run_parallel_pair(gpu0_task, gpu1_task):
    """ë‘ ê°œì˜ ì‹¤í—˜ì„ ë³‘ë ¬ë¡œ ì‹¤í–‰"""
    p0 = run_on_gpu(0, *gpu0_task) if gpu0_task else None
    p1 = run_on_gpu(1, *gpu1_task) if gpu1_task else None
    
    success0 = wait_and_mark(p0, gpu0_task[2]) if gpu0_task else True
    success1 = wait_and_mark(p1, gpu1_task[2]) if gpu1_task else True
    
    return success0 and success1

# ================================================
# Phase 1: ì•„í‚¤í…ì²˜ ë¹„êµ (10 ì‹¤í—˜)
# ================================================
def run_phase1():
    log_phase("PHASE 1: Architecture Comparison")
    
    models = [
        ("klue/bert-base", "bert", "2e-5", "64", "32"),
        ("klue/roberta-base", "roberta", "2e-5", "64", "32"),
        ("monologg/koelectra-base-v3-discriminator", "electra", "3e-5", "64", "32"),
        ("monologg/distilkobert", "distilbert", "5e-5", "128", "64"),
        ("team-lucid/deberta-v3-base-korean", "deberta", "1e-5", "32", "16"),
    ]
    
    for model_id, model_name, lr, batch_noctx, batch_ctx in models:
        noctx_name = f"{model_name}-noctx"
        ctx_name = f"{model_name}-ctx"
        
        # GPU 0: noctx, GPU 1: ctx ë³‘ë ¬ ì‹¤í–‰
        noctx_task = (
            "scripts/train.py",
            ["--model", model_id, "--loss_type", "bce", "--learning_rate", lr,
             "--batch_size", batch_noctx, "--num_epochs", "3", "--no_context", "--max_length", "128"],
            noctx_name
        )
        
        ctx_task = (
            "scripts/train.py",
            ["--model", model_id, "--loss_type", "bce", "--learning_rate", lr,
             "--batch_size", batch_ctx, "--num_epochs", "3", "--use_context", "--max_length", "512"],
            ctx_name
        )
        
        if not run_parallel_pair(noctx_task, ctx_task):
            log_error(f"{model_name} ì‹¤í—˜ ì‹¤íŒ¨")
            return False
    
    log_ok("Phase 1 ì™„ë£Œ!")
    return True

# ================================================
# Phase 1 ê²°ê³¼ ë¶„ì„ ë° Best Model ì„ ì •
# ================================================
def get_best_model_from_phase1():
    """Phase 1 ê²°ê³¼ì—ì„œ Best Model ì„ ì • (Macro F1 ê¸°ì¤€)"""
    log_info("Phase 1 ê²°ê³¼ ë¶„ì„ ì¤‘...")
    
    results = []
    RESULTS_DIR.mkdir(parents=True, exist_ok=True)
    
    # ctx ì‹¤í—˜ ê²°ê³¼ë§Œ ë¹„êµ (ì‹¤ì œ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤)
    ctx_experiments = ["bert-ctx", "roberta-ctx", "electra-ctx", "distilbert-ctx", "deberta-ctx"]
    
    model_map = {
        "bert-ctx": "klue/bert-base",
        "roberta-ctx": "klue/roberta-base",
        "electra-ctx": "monologg/koelectra-base-v3-discriminator",
        "distilbert-ctx": "monologg/distilkobert",
        "deberta-ctx": "team-lucid/deberta-v3-base-korean",
    }
    
    for exp_name in ctx_experiments:
        result_file = RESULTS_DIR / f"{exp_name}_results.json"
        if result_file.exists():
            with open(result_file) as f:
                data = json.load(f)
                results.append({
                    "name": exp_name,
                    "model": model_map[exp_name],
                    "macro_f1": data.get("eval_macro_f1", data.get("macro_f1", 0)),
                    "eval_loss": data.get("eval_loss", float('inf'))
                })
                log_info(f"  {exp_name}: macro_f1={results[-1]['macro_f1']:.4f}")
    
    if not results:
        log_error("Phase 1 ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ. ê¸°ë³¸ê°’ RoBERTa ì‚¬ìš©")
        return "klue/roberta-base", "2e-5"
    
    # Macro F1 ë‚´ë¦¼ì°¨ìˆœ, eval_loss ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬
    results.sort(key=lambda x: (-x['macro_f1'], x['eval_loss']))
    
    best = results[0]
    log_ok(f"Best Model: {best['name']} (macro_f1={best['macro_f1']:.4f})")
    
    # Learning rate ë§¤í•‘
    lr_map = {
        "klue/bert-base": "2e-5",
        "klue/roberta-base": "2e-5",
        "monologg/koelectra-base-v3-discriminator": "3e-5",
        "monologg/distilkobert": "5e-5",
        "team-lucid/deberta-v3-base-korean": "1e-5",
    }
    
    return best['model'], lr_map.get(best['model'], "2e-5")

# ================================================
# Phase 2: Loss í•¨ìˆ˜ ë¹„êµ (Best Model Ã— 4 Loss)
# ================================================
def run_phase2(best_model, best_lr):
    log_phase(f"PHASE 2: Loss Function Study ({best_model.split('/')[-1]})")
    
    # BCEëŠ” Phase 1ì—ì„œ ì´ë¯¸ ìˆ˜í–‰ë¨ (ì¤‘ë³µ ì œê±°)
    losses = [
        ("soft_bce", "loss-softbce"),
        ("focal", "loss-focal"),
        ("asl", "loss-asl"),
        ("criterion_weighted", "loss-weighted"),
    ]
    
    # 2ê°œì”© ë³‘ë ¬ ì‹¤í–‰
    for i in range(0, len(losses), 2):
        tasks = []
        for j in range(2):
            if i + j < len(losses):
                loss_type, name = losses[i + j]
                tasks.append((
                    "scripts/train.py",
                    ["--model", best_model, "--loss_type", loss_type, "--learning_rate", best_lr,
                     "--batch_size", "32", "--num_epochs", "3", "--use_context", "--max_length", "512"],
                    name
                ))
        
        gpu0_task = tasks[0] if len(tasks) > 0 else None
        gpu1_task = tasks[1] if len(tasks) > 1 else None
        
        if not run_parallel_pair(gpu0_task, gpu1_task):
            return False
    
    log_ok("Phase 2 ì™„ë£Œ!")
    return True

# ================================================
# Phase 3: ê³ ê¸‰ ì•„í‚¤í…ì²˜ (ë³‘ë ¬)
# ================================================
def run_phase3(best_model, best_lr):
    log_phase(f"PHASE 3: Advanced Architecture ({best_model.split('/')[-1]})")
    
    multihead_task = (
        "scripts/train_multihead.py",
        ["--model", best_model, "--loss_type", "soft_bce", "--learning_rate", best_lr,
         "--batch_size", "24", "--num_epochs", "3", "--use_context", "--max_length", "512"],
        "arch-multihead"
    )
    
    crossenc_task = (
        "scripts/train_crossencoder.py",
        ["--model", best_model, "--loss_type", "soft_bce", "--learning_rate", best_lr,
         "--batch_size", "16", "--num_epochs", "3", "--use_context", "--max_length", "512"],
        "arch-crossenc"
    )
    
    if not run_parallel_pair(multihead_task, crossenc_task):
        return False
    
    log_ok("Phase 3 ì™„ë£Œ!")
    return True

# ================================================
# Phase 4: í•™ìŠµ ì „ëµ (ìˆœì°¨)
# ================================================
def run_phase4(best_model, best_lr):
    log_phase(f"PHASE 4: Learning Strategy ({best_model.split('/')[-1]})")
    
    experiments = [
        ("scripts/train_curriculum.py",
         ["--model", best_model, "--loss_type", "soft_bce", "--learning_rate", best_lr,
          "--batch_size", "32", "--num_epochs", "5", "--use_context", "--max_length", "512", "--strategy", "sqrt"],
         "strat-curriculum"),
        ("scripts/train_contrastive.py",
         ["--model", best_model, "--learning_rate", best_lr,
          "--batch_size", "32", "--num_epochs", "3", "--use_context", "--max_length", "512",
          "--lambda_contrastive", "0.1", "--projection_dim", "256"],
         "strat-contrastive"),
    ]
    
    # ìˆœì°¨ ì‹¤í–‰ (ë©”ëª¨ë¦¬ ë§ì´ ì‚¬ìš©)
    for script, args, name in experiments:
        p = run_on_gpu(0, script, args, name)
        if not wait_and_mark(p, name):
            return False
    
    log_ok("Phase 4 ì™„ë£Œ!")
    return True

# ================================================
# ë©”ì¸
# ================================================
def main():
    log_phase("mutsa-v2 Experiment (2-GPU Parallel)")
    log_info("í™˜ê²½: Threadripper PRO 7975WX + 2Ã— RTX 3090")
    
    os.system("nvidia-smi --query-gpu=index,memory.used --format=csv")
    
    start_time = time.time()
    
    # Phase 1: ì•„í‚¤í…ì²˜ ë¹„êµ
    if not run_phase1():
        log_error("Phase 1 ì‹¤íŒ¨")
        return 1
    
    # Best Model ì„ ì •
    best_model, best_lr = get_best_model_from_phase1()
    
    # Phase 2: Loss í•¨ìˆ˜ ë¹„êµ
    if not run_phase2(best_model, best_lr):
        log_error("Phase 2 ì‹¤íŒ¨")
        return 1
    
    # Phase 3: ê³ ê¸‰ ì•„í‚¤í…ì²˜
    if not run_phase3(best_model, best_lr):
        log_error("Phase 3 ì‹¤íŒ¨")
        return 1
    
    # Phase 4: í•™ìŠµ ì „ëµ
    if not run_phase4(best_model, best_lr):
        log_error("Phase 4 ì‹¤íŒ¨")
        return 1
    
    elapsed = int((time.time() - start_time) / 60)
    
    log_phase("COMPLETE")
    print(f"ğŸ“Š wandb: https://wandb.ai/dhj9842-hanyang-university/mutsa-v2")
    log_ok(f"ì´ ì†Œìš”: {elapsed}ë¶„")
    
    return 0

if __name__ == "__main__":
    sys.exit(main())
